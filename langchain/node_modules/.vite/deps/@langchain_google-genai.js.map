{
  "version": 3,
  "sources": ["../../@google/generative-ai/dist/index.mjs", "../../@langchain/google-genai/dist/utils/zod_to_genai_parameters.js", "../../@langchain/google-genai/dist/utils/common.js", "../../@langchain/google-genai/dist/output_parsers.js", "../../@langchain/google-genai/dist/utils/tools.js", "../../@langchain/google-genai/dist/chat_models.js", "../../@langchain/google-genai/dist/embeddings.js"],
  "sourcesContent": ["/**\n * Contains the list of OpenAPI data types\n * as defined by https://swagger.io/docs/specification/data-models/data-types/\n * @public\n */\nvar SchemaType;\n(function (SchemaType) {\n    /** String type. */\n    SchemaType[\"STRING\"] = \"string\";\n    /** Number type. */\n    SchemaType[\"NUMBER\"] = \"number\";\n    /** Integer type. */\n    SchemaType[\"INTEGER\"] = \"integer\";\n    /** Boolean type. */\n    SchemaType[\"BOOLEAN\"] = \"boolean\";\n    /** Array type. */\n    SchemaType[\"ARRAY\"] = \"array\";\n    /** Object type. */\n    SchemaType[\"OBJECT\"] = \"object\";\n})(SchemaType || (SchemaType = {}));\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * @public\n */\nvar ExecutableCodeLanguage;\n(function (ExecutableCodeLanguage) {\n    ExecutableCodeLanguage[\"LANGUAGE_UNSPECIFIED\"] = \"language_unspecified\";\n    ExecutableCodeLanguage[\"PYTHON\"] = \"python\";\n})(ExecutableCodeLanguage || (ExecutableCodeLanguage = {}));\n/**\n * Possible outcomes of code execution.\n * @public\n */\nvar Outcome;\n(function (Outcome) {\n    /**\n     * Unspecified status. This value should not be used.\n     */\n    Outcome[\"OUTCOME_UNSPECIFIED\"] = \"outcome_unspecified\";\n    /**\n     * Code execution completed successfully.\n     */\n    Outcome[\"OUTCOME_OK\"] = \"outcome_ok\";\n    /**\n     * Code execution finished but with a failure. `stderr` should contain the\n     * reason.\n     */\n    Outcome[\"OUTCOME_FAILED\"] = \"outcome_failed\";\n    /**\n     * Code execution ran for too long, and was cancelled. There may or may not\n     * be a partial output present.\n     */\n    Outcome[\"OUTCOME_DEADLINE_EXCEEDED\"] = \"outcome_deadline_exceeded\";\n})(Outcome || (Outcome = {}));\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Possible roles.\n * @public\n */\nconst POSSIBLE_ROLES = [\"user\", \"model\", \"function\", \"system\"];\n/**\n * Harm categories that would cause prompts or candidates to be blocked.\n * @public\n */\nvar HarmCategory;\n(function (HarmCategory) {\n    HarmCategory[\"HARM_CATEGORY_UNSPECIFIED\"] = \"HARM_CATEGORY_UNSPECIFIED\";\n    HarmCategory[\"HARM_CATEGORY_HATE_SPEECH\"] = \"HARM_CATEGORY_HATE_SPEECH\";\n    HarmCategory[\"HARM_CATEGORY_SEXUALLY_EXPLICIT\"] = \"HARM_CATEGORY_SEXUALLY_EXPLICIT\";\n    HarmCategory[\"HARM_CATEGORY_HARASSMENT\"] = \"HARM_CATEGORY_HARASSMENT\";\n    HarmCategory[\"HARM_CATEGORY_DANGEROUS_CONTENT\"] = \"HARM_CATEGORY_DANGEROUS_CONTENT\";\n})(HarmCategory || (HarmCategory = {}));\n/**\n * Threshold above which a prompt or candidate will be blocked.\n * @public\n */\nvar HarmBlockThreshold;\n(function (HarmBlockThreshold) {\n    // Threshold is unspecified.\n    HarmBlockThreshold[\"HARM_BLOCK_THRESHOLD_UNSPECIFIED\"] = \"HARM_BLOCK_THRESHOLD_UNSPECIFIED\";\n    // Content with NEGLIGIBLE will be allowed.\n    HarmBlockThreshold[\"BLOCK_LOW_AND_ABOVE\"] = \"BLOCK_LOW_AND_ABOVE\";\n    // Content with NEGLIGIBLE and LOW will be allowed.\n    HarmBlockThreshold[\"BLOCK_MEDIUM_AND_ABOVE\"] = \"BLOCK_MEDIUM_AND_ABOVE\";\n    // Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed.\n    HarmBlockThreshold[\"BLOCK_ONLY_HIGH\"] = \"BLOCK_ONLY_HIGH\";\n    // All content will be allowed.\n    HarmBlockThreshold[\"BLOCK_NONE\"] = \"BLOCK_NONE\";\n})(HarmBlockThreshold || (HarmBlockThreshold = {}));\n/**\n * Probability that a prompt or candidate matches a harm category.\n * @public\n */\nvar HarmProbability;\n(function (HarmProbability) {\n    // Probability is unspecified.\n    HarmProbability[\"HARM_PROBABILITY_UNSPECIFIED\"] = \"HARM_PROBABILITY_UNSPECIFIED\";\n    // Content has a negligible chance of being unsafe.\n    HarmProbability[\"NEGLIGIBLE\"] = \"NEGLIGIBLE\";\n    // Content has a low chance of being unsafe.\n    HarmProbability[\"LOW\"] = \"LOW\";\n    // Content has a medium chance of being unsafe.\n    HarmProbability[\"MEDIUM\"] = \"MEDIUM\";\n    // Content has a high chance of being unsafe.\n    HarmProbability[\"HIGH\"] = \"HIGH\";\n})(HarmProbability || (HarmProbability = {}));\n/**\n * Reason that a prompt was blocked.\n * @public\n */\nvar BlockReason;\n(function (BlockReason) {\n    // A blocked reason was not specified.\n    BlockReason[\"BLOCKED_REASON_UNSPECIFIED\"] = \"BLOCKED_REASON_UNSPECIFIED\";\n    // Content was blocked by safety settings.\n    BlockReason[\"SAFETY\"] = \"SAFETY\";\n    // Content was blocked, but the reason is uncategorized.\n    BlockReason[\"OTHER\"] = \"OTHER\";\n})(BlockReason || (BlockReason = {}));\n/**\n * Reason that a candidate finished.\n * @public\n */\nvar FinishReason;\n(function (FinishReason) {\n    // Default value. This value is unused.\n    FinishReason[\"FINISH_REASON_UNSPECIFIED\"] = \"FINISH_REASON_UNSPECIFIED\";\n    // Natural stop point of the model or provided stop sequence.\n    FinishReason[\"STOP\"] = \"STOP\";\n    // The maximum number of tokens as specified in the request was reached.\n    FinishReason[\"MAX_TOKENS\"] = \"MAX_TOKENS\";\n    // The candidate content was flagged for safety reasons.\n    FinishReason[\"SAFETY\"] = \"SAFETY\";\n    // The candidate content was flagged for recitation reasons.\n    FinishReason[\"RECITATION\"] = \"RECITATION\";\n    // The candidate content was flagged for using an unsupported language.\n    FinishReason[\"LANGUAGE\"] = \"LANGUAGE\";\n    // Unknown reason.\n    FinishReason[\"OTHER\"] = \"OTHER\";\n})(FinishReason || (FinishReason = {}));\n/**\n * Task type for embedding content.\n * @public\n */\nvar TaskType;\n(function (TaskType) {\n    TaskType[\"TASK_TYPE_UNSPECIFIED\"] = \"TASK_TYPE_UNSPECIFIED\";\n    TaskType[\"RETRIEVAL_QUERY\"] = \"RETRIEVAL_QUERY\";\n    TaskType[\"RETRIEVAL_DOCUMENT\"] = \"RETRIEVAL_DOCUMENT\";\n    TaskType[\"SEMANTIC_SIMILARITY\"] = \"SEMANTIC_SIMILARITY\";\n    TaskType[\"CLASSIFICATION\"] = \"CLASSIFICATION\";\n    TaskType[\"CLUSTERING\"] = \"CLUSTERING\";\n})(TaskType || (TaskType = {}));\n/**\n * @public\n */\nvar FunctionCallingMode;\n(function (FunctionCallingMode) {\n    // Unspecified function calling mode. This value should not be used.\n    FunctionCallingMode[\"MODE_UNSPECIFIED\"] = \"MODE_UNSPECIFIED\";\n    // Default model behavior, model decides to predict either a function call\n    // or a natural language repspose.\n    FunctionCallingMode[\"AUTO\"] = \"AUTO\";\n    // Model is constrained to always predicting a function call only.\n    // If \"allowed_function_names\" are set, the predicted function call will be\n    // limited to any one of \"allowed_function_names\", else the predicted\n    // function call will be any one of the provided \"function_declarations\".\n    FunctionCallingMode[\"ANY\"] = \"ANY\";\n    // Model will not predict any function call. Model behavior is same as when\n    // not passing any function declarations.\n    FunctionCallingMode[\"NONE\"] = \"NONE\";\n})(FunctionCallingMode || (FunctionCallingMode = {}));\n/**\n * The mode of the predictor to be used in dynamic retrieval.\n * @public\n */\nvar DynamicRetrievalMode;\n(function (DynamicRetrievalMode) {\n    // Unspecified function calling mode. This value should not be used.\n    DynamicRetrievalMode[\"MODE_UNSPECIFIED\"] = \"MODE_UNSPECIFIED\";\n    // Run retrieval only when system decides it is necessary.\n    DynamicRetrievalMode[\"MODE_DYNAMIC\"] = \"MODE_DYNAMIC\";\n})(DynamicRetrievalMode || (DynamicRetrievalMode = {}));\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Basic error type for this SDK.\n * @public\n */\nclass GoogleGenerativeAIError extends Error {\n    constructor(message) {\n        super(`[GoogleGenerativeAI Error]: ${message}`);\n    }\n}\n/**\n * Errors in the contents of a response from the model. This includes parsing\n * errors, or responses including a safety block reason.\n * @public\n */\nclass GoogleGenerativeAIResponseError extends GoogleGenerativeAIError {\n    constructor(message, response) {\n        super(message);\n        this.response = response;\n    }\n}\n/**\n * Error class covering HTTP errors when calling the server. Includes HTTP\n * status, statusText, and optional details, if provided in the server response.\n * @public\n */\nclass GoogleGenerativeAIFetchError extends GoogleGenerativeAIError {\n    constructor(message, status, statusText, errorDetails) {\n        super(message);\n        this.status = status;\n        this.statusText = statusText;\n        this.errorDetails = errorDetails;\n    }\n}\n/**\n * Errors in the contents of a request originating from user input.\n * @public\n */\nclass GoogleGenerativeAIRequestInputError extends GoogleGenerativeAIError {\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst DEFAULT_BASE_URL = \"https://generativelanguage.googleapis.com\";\nconst DEFAULT_API_VERSION = \"v1beta\";\n/**\n * We can't `require` package.json if this runs on web. We will use rollup to\n * swap in the version number here at build time.\n */\nconst PACKAGE_VERSION = \"0.21.0\";\nconst PACKAGE_LOG_HEADER = \"genai-js\";\nvar Task;\n(function (Task) {\n    Task[\"GENERATE_CONTENT\"] = \"generateContent\";\n    Task[\"STREAM_GENERATE_CONTENT\"] = \"streamGenerateContent\";\n    Task[\"COUNT_TOKENS\"] = \"countTokens\";\n    Task[\"EMBED_CONTENT\"] = \"embedContent\";\n    Task[\"BATCH_EMBED_CONTENTS\"] = \"batchEmbedContents\";\n})(Task || (Task = {}));\nclass RequestUrl {\n    constructor(model, task, apiKey, stream, requestOptions) {\n        this.model = model;\n        this.task = task;\n        this.apiKey = apiKey;\n        this.stream = stream;\n        this.requestOptions = requestOptions;\n    }\n    toString() {\n        var _a, _b;\n        const apiVersion = ((_a = this.requestOptions) === null || _a === void 0 ? void 0 : _a.apiVersion) || DEFAULT_API_VERSION;\n        const baseUrl = ((_b = this.requestOptions) === null || _b === void 0 ? void 0 : _b.baseUrl) || DEFAULT_BASE_URL;\n        let url = `${baseUrl}/${apiVersion}/${this.model}:${this.task}`;\n        if (this.stream) {\n            url += \"?alt=sse\";\n        }\n        return url;\n    }\n}\n/**\n * Simple, but may become more complex if we add more versions to log.\n */\nfunction getClientHeaders(requestOptions) {\n    const clientHeaders = [];\n    if (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiClient) {\n        clientHeaders.push(requestOptions.apiClient);\n    }\n    clientHeaders.push(`${PACKAGE_LOG_HEADER}/${PACKAGE_VERSION}`);\n    return clientHeaders.join(\" \");\n}\nasync function getHeaders(url) {\n    var _a;\n    const headers = new Headers();\n    headers.append(\"Content-Type\", \"application/json\");\n    headers.append(\"x-goog-api-client\", getClientHeaders(url.requestOptions));\n    headers.append(\"x-goog-api-key\", url.apiKey);\n    let customHeaders = (_a = url.requestOptions) === null || _a === void 0 ? void 0 : _a.customHeaders;\n    if (customHeaders) {\n        if (!(customHeaders instanceof Headers)) {\n            try {\n                customHeaders = new Headers(customHeaders);\n            }\n            catch (e) {\n                throw new GoogleGenerativeAIRequestInputError(`unable to convert customHeaders value ${JSON.stringify(customHeaders)} to Headers: ${e.message}`);\n            }\n        }\n        for (const [headerName, headerValue] of customHeaders.entries()) {\n            if (headerName === \"x-goog-api-key\") {\n                throw new GoogleGenerativeAIRequestInputError(`Cannot set reserved header name ${headerName}`);\n            }\n            else if (headerName === \"x-goog-api-client\") {\n                throw new GoogleGenerativeAIRequestInputError(`Header name ${headerName} can only be set using the apiClient field`);\n            }\n            headers.append(headerName, headerValue);\n        }\n    }\n    return headers;\n}\nasync function constructModelRequest(model, task, apiKey, stream, body, requestOptions) {\n    const url = new RequestUrl(model, task, apiKey, stream, requestOptions);\n    return {\n        url: url.toString(),\n        fetchOptions: Object.assign(Object.assign({}, buildFetchOptions(requestOptions)), { method: \"POST\", headers: await getHeaders(url), body }),\n    };\n}\nasync function makeModelRequest(model, task, apiKey, stream, body, requestOptions = {}, \n// Allows this to be stubbed for tests\nfetchFn = fetch) {\n    const { url, fetchOptions } = await constructModelRequest(model, task, apiKey, stream, body, requestOptions);\n    return makeRequest(url, fetchOptions, fetchFn);\n}\nasync function makeRequest(url, fetchOptions, fetchFn = fetch) {\n    let response;\n    try {\n        response = await fetchFn(url, fetchOptions);\n    }\n    catch (e) {\n        handleResponseError(e, url);\n    }\n    if (!response.ok) {\n        await handleResponseNotOk(response, url);\n    }\n    return response;\n}\nfunction handleResponseError(e, url) {\n    let err = e;\n    if (!(e instanceof GoogleGenerativeAIFetchError ||\n        e instanceof GoogleGenerativeAIRequestInputError)) {\n        err = new GoogleGenerativeAIError(`Error fetching from ${url.toString()}: ${e.message}`);\n        err.stack = e.stack;\n    }\n    throw err;\n}\nasync function handleResponseNotOk(response, url) {\n    let message = \"\";\n    let errorDetails;\n    try {\n        const json = await response.json();\n        message = json.error.message;\n        if (json.error.details) {\n            message += ` ${JSON.stringify(json.error.details)}`;\n            errorDetails = json.error.details;\n        }\n    }\n    catch (e) {\n        // ignored\n    }\n    throw new GoogleGenerativeAIFetchError(`Error fetching from ${url.toString()}: [${response.status} ${response.statusText}] ${message}`, response.status, response.statusText, errorDetails);\n}\n/**\n * Generates the request options to be passed to the fetch API.\n * @param requestOptions - The user-defined request options.\n * @returns The generated request options.\n */\nfunction buildFetchOptions(requestOptions) {\n    const fetchOptions = {};\n    if ((requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.signal) !== undefined || (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeout) >= 0) {\n        const controller = new AbortController();\n        if ((requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeout) >= 0) {\n            setTimeout(() => controller.abort(), requestOptions.timeout);\n        }\n        if (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.signal) {\n            requestOptions.signal.addEventListener(\"abort\", () => {\n                controller.abort();\n            });\n        }\n        fetchOptions.signal = controller.signal;\n    }\n    return fetchOptions;\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Adds convenience helper methods to a response object, including stream\n * chunks (as long as each chunk is a complete GenerateContentResponse JSON).\n */\nfunction addHelpers(response) {\n    response.text = () => {\n        if (response.candidates && response.candidates.length > 0) {\n            if (response.candidates.length > 1) {\n                console.warn(`This response had ${response.candidates.length} ` +\n                    `candidates. Returning text from the first candidate only. ` +\n                    `Access response.candidates directly to use the other candidates.`);\n            }\n            if (hadBadFinishReason(response.candidates[0])) {\n                throw new GoogleGenerativeAIResponseError(`${formatBlockErrorMessage(response)}`, response);\n            }\n            return getText(response);\n        }\n        else if (response.promptFeedback) {\n            throw new GoogleGenerativeAIResponseError(`Text not available. ${formatBlockErrorMessage(response)}`, response);\n        }\n        return \"\";\n    };\n    /**\n     * TODO: remove at next major version\n     */\n    response.functionCall = () => {\n        if (response.candidates && response.candidates.length > 0) {\n            if (response.candidates.length > 1) {\n                console.warn(`This response had ${response.candidates.length} ` +\n                    `candidates. Returning function calls from the first candidate only. ` +\n                    `Access response.candidates directly to use the other candidates.`);\n            }\n            if (hadBadFinishReason(response.candidates[0])) {\n                throw new GoogleGenerativeAIResponseError(`${formatBlockErrorMessage(response)}`, response);\n            }\n            console.warn(`response.functionCall() is deprecated. ` +\n                `Use response.functionCalls() instead.`);\n            return getFunctionCalls(response)[0];\n        }\n        else if (response.promptFeedback) {\n            throw new GoogleGenerativeAIResponseError(`Function call not available. ${formatBlockErrorMessage(response)}`, response);\n        }\n        return undefined;\n    };\n    response.functionCalls = () => {\n        if (response.candidates && response.candidates.length > 0) {\n            if (response.candidates.length > 1) {\n                console.warn(`This response had ${response.candidates.length} ` +\n                    `candidates. Returning function calls from the first candidate only. ` +\n                    `Access response.candidates directly to use the other candidates.`);\n            }\n            if (hadBadFinishReason(response.candidates[0])) {\n                throw new GoogleGenerativeAIResponseError(`${formatBlockErrorMessage(response)}`, response);\n            }\n            return getFunctionCalls(response);\n        }\n        else if (response.promptFeedback) {\n            throw new GoogleGenerativeAIResponseError(`Function call not available. ${formatBlockErrorMessage(response)}`, response);\n        }\n        return undefined;\n    };\n    return response;\n}\n/**\n * Returns all text found in all parts of first candidate.\n */\nfunction getText(response) {\n    var _a, _b, _c, _d;\n    const textStrings = [];\n    if ((_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0].content) === null || _b === void 0 ? void 0 : _b.parts) {\n        for (const part of (_d = (_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0].content) === null || _d === void 0 ? void 0 : _d.parts) {\n            if (part.text) {\n                textStrings.push(part.text);\n            }\n            if (part.executableCode) {\n                textStrings.push(\"\\n```\" +\n                    part.executableCode.language +\n                    \"\\n\" +\n                    part.executableCode.code +\n                    \"\\n```\\n\");\n            }\n            if (part.codeExecutionResult) {\n                textStrings.push(\"\\n```\\n\" + part.codeExecutionResult.output + \"\\n```\\n\");\n            }\n        }\n    }\n    if (textStrings.length > 0) {\n        return textStrings.join(\"\");\n    }\n    else {\n        return \"\";\n    }\n}\n/**\n * Returns functionCall of first candidate.\n */\nfunction getFunctionCalls(response) {\n    var _a, _b, _c, _d;\n    const functionCalls = [];\n    if ((_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0].content) === null || _b === void 0 ? void 0 : _b.parts) {\n        for (const part of (_d = (_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0].content) === null || _d === void 0 ? void 0 : _d.parts) {\n            if (part.functionCall) {\n                functionCalls.push(part.functionCall);\n            }\n        }\n    }\n    if (functionCalls.length > 0) {\n        return functionCalls;\n    }\n    else {\n        return undefined;\n    }\n}\nconst badFinishReasons = [\n    FinishReason.RECITATION,\n    FinishReason.SAFETY,\n    FinishReason.LANGUAGE,\n];\nfunction hadBadFinishReason(candidate) {\n    return (!!candidate.finishReason &&\n        badFinishReasons.includes(candidate.finishReason));\n}\nfunction formatBlockErrorMessage(response) {\n    var _a, _b, _c;\n    let message = \"\";\n    if ((!response.candidates || response.candidates.length === 0) &&\n        response.promptFeedback) {\n        message += \"Response was blocked\";\n        if ((_a = response.promptFeedback) === null || _a === void 0 ? void 0 : _a.blockReason) {\n            message += ` due to ${response.promptFeedback.blockReason}`;\n        }\n        if ((_b = response.promptFeedback) === null || _b === void 0 ? void 0 : _b.blockReasonMessage) {\n            message += `: ${response.promptFeedback.blockReasonMessage}`;\n        }\n    }\n    else if ((_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0]) {\n        const firstCandidate = response.candidates[0];\n        if (hadBadFinishReason(firstCandidate)) {\n            message += `Candidate was blocked due to ${firstCandidate.finishReason}`;\n            if (firstCandidate.finishMessage) {\n                message += `: ${firstCandidate.finishMessage}`;\n            }\n        }\n    }\n    return message;\n}\n\n/******************************************************************************\r\nCopyright (c) Microsoft Corporation.\r\n\r\nPermission to use, copy, modify, and/or distribute this software for any\r\npurpose with or without fee is hereby granted.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\r\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\r\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\r\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\r\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\r\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\r\nPERFORMANCE OF THIS SOFTWARE.\r\n***************************************************************************** */\r\n/* global Reflect, Promise, SuppressedError, Symbol */\r\n\r\n\r\nfunction __await(v) {\r\n    return this instanceof __await ? (this.v = v, this) : new __await(v);\r\n}\r\n\r\nfunction __asyncGenerator(thisArg, _arguments, generator) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var g = generator.apply(thisArg, _arguments || []), i, q = [];\r\n    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\r\n    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\r\n    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\r\n    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\r\n    function fulfill(value) { resume(\"next\", value); }\r\n    function reject(value) { resume(\"throw\", value); }\r\n    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\r\n}\r\n\r\ntypeof SuppressedError === \"function\" ? SuppressedError : function (error, suppressed, message) {\r\n    var e = new Error(message);\r\n    return e.name = \"SuppressedError\", e.error = error, e.suppressed = suppressed, e;\r\n};\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst responseLineRE = /^data\\: (.*)(?:\\n\\n|\\r\\r|\\r\\n\\r\\n)/;\n/**\n * Process a response.body stream from the backend and return an\n * iterator that provides one complete GenerateContentResponse at a time\n * and a promise that resolves with a single aggregated\n * GenerateContentResponse.\n *\n * @param response - Response from a fetch call\n */\nfunction processStream(response) {\n    const inputStream = response.body.pipeThrough(new TextDecoderStream(\"utf8\", { fatal: true }));\n    const responseStream = getResponseStream(inputStream);\n    const [stream1, stream2] = responseStream.tee();\n    return {\n        stream: generateResponseSequence(stream1),\n        response: getResponsePromise(stream2),\n    };\n}\nasync function getResponsePromise(stream) {\n    const allResponses = [];\n    const reader = stream.getReader();\n    while (true) {\n        const { done, value } = await reader.read();\n        if (done) {\n            return addHelpers(aggregateResponses(allResponses));\n        }\n        allResponses.push(value);\n    }\n}\nfunction generateResponseSequence(stream) {\n    return __asyncGenerator(this, arguments, function* generateResponseSequence_1() {\n        const reader = stream.getReader();\n        while (true) {\n            const { value, done } = yield __await(reader.read());\n            if (done) {\n                break;\n            }\n            yield yield __await(addHelpers(value));\n        }\n    });\n}\n/**\n * Reads a raw stream from the fetch response and join incomplete\n * chunks, returning a new stream that provides a single complete\n * GenerateContentResponse in each iteration.\n */\nfunction getResponseStream(inputStream) {\n    const reader = inputStream.getReader();\n    const stream = new ReadableStream({\n        start(controller) {\n            let currentText = \"\";\n            return pump();\n            function pump() {\n                return reader.read().then(({ value, done }) => {\n                    if (done) {\n                        if (currentText.trim()) {\n                            controller.error(new GoogleGenerativeAIError(\"Failed to parse stream\"));\n                            return;\n                        }\n                        controller.close();\n                        return;\n                    }\n                    currentText += value;\n                    let match = currentText.match(responseLineRE);\n                    let parsedResponse;\n                    while (match) {\n                        try {\n                            parsedResponse = JSON.parse(match[1]);\n                        }\n                        catch (e) {\n                            controller.error(new GoogleGenerativeAIError(`Error parsing JSON response: \"${match[1]}\"`));\n                            return;\n                        }\n                        controller.enqueue(parsedResponse);\n                        currentText = currentText.substring(match[0].length);\n                        match = currentText.match(responseLineRE);\n                    }\n                    return pump();\n                });\n            }\n        },\n    });\n    return stream;\n}\n/**\n * Aggregates an array of `GenerateContentResponse`s into a single\n * GenerateContentResponse.\n */\nfunction aggregateResponses(responses) {\n    const lastResponse = responses[responses.length - 1];\n    const aggregatedResponse = {\n        promptFeedback: lastResponse === null || lastResponse === void 0 ? void 0 : lastResponse.promptFeedback,\n    };\n    for (const response of responses) {\n        if (response.candidates) {\n            for (const candidate of response.candidates) {\n                const i = candidate.index;\n                if (!aggregatedResponse.candidates) {\n                    aggregatedResponse.candidates = [];\n                }\n                if (!aggregatedResponse.candidates[i]) {\n                    aggregatedResponse.candidates[i] = {\n                        index: candidate.index,\n                    };\n                }\n                // Keep overwriting, the last one will be final\n                aggregatedResponse.candidates[i].citationMetadata =\n                    candidate.citationMetadata;\n                aggregatedResponse.candidates[i].groundingMetadata =\n                    candidate.groundingMetadata;\n                aggregatedResponse.candidates[i].finishReason = candidate.finishReason;\n                aggregatedResponse.candidates[i].finishMessage =\n                    candidate.finishMessage;\n                aggregatedResponse.candidates[i].safetyRatings =\n                    candidate.safetyRatings;\n                /**\n                 * Candidates should always have content and parts, but this handles\n                 * possible malformed responses.\n                 */\n                if (candidate.content && candidate.content.parts) {\n                    if (!aggregatedResponse.candidates[i].content) {\n                        aggregatedResponse.candidates[i].content = {\n                            role: candidate.content.role || \"user\",\n                            parts: [],\n                        };\n                    }\n                    const newPart = {};\n                    for (const part of candidate.content.parts) {\n                        if (part.text) {\n                            newPart.text = part.text;\n                        }\n                        if (part.functionCall) {\n                            newPart.functionCall = part.functionCall;\n                        }\n                        if (part.executableCode) {\n                            newPart.executableCode = part.executableCode;\n                        }\n                        if (part.codeExecutionResult) {\n                            newPart.codeExecutionResult = part.codeExecutionResult;\n                        }\n                        if (Object.keys(newPart).length === 0) {\n                            newPart.text = \"\";\n                        }\n                        aggregatedResponse.candidates[i].content.parts.push(newPart);\n                    }\n                }\n            }\n        }\n        if (response.usageMetadata) {\n            aggregatedResponse.usageMetadata = response.usageMetadata;\n        }\n    }\n    return aggregatedResponse;\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nasync function generateContentStream(apiKey, model, params, requestOptions) {\n    const response = await makeModelRequest(model, Task.STREAM_GENERATE_CONTENT, apiKey, \n    /* stream */ true, JSON.stringify(params), requestOptions);\n    return processStream(response);\n}\nasync function generateContent(apiKey, model, params, requestOptions) {\n    const response = await makeModelRequest(model, Task.GENERATE_CONTENT, apiKey, \n    /* stream */ false, JSON.stringify(params), requestOptions);\n    const responseJson = await response.json();\n    const enhancedResponse = addHelpers(responseJson);\n    return {\n        response: enhancedResponse,\n    };\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nfunction formatSystemInstruction(input) {\n    // null or undefined\n    if (input == null) {\n        return undefined;\n    }\n    else if (typeof input === \"string\") {\n        return { role: \"system\", parts: [{ text: input }] };\n    }\n    else if (input.text) {\n        return { role: \"system\", parts: [input] };\n    }\n    else if (input.parts) {\n        if (!input.role) {\n            return { role: \"system\", parts: input.parts };\n        }\n        else {\n            return input;\n        }\n    }\n}\nfunction formatNewContent(request) {\n    let newParts = [];\n    if (typeof request === \"string\") {\n        newParts = [{ text: request }];\n    }\n    else {\n        for (const partOrString of request) {\n            if (typeof partOrString === \"string\") {\n                newParts.push({ text: partOrString });\n            }\n            else {\n                newParts.push(partOrString);\n            }\n        }\n    }\n    return assignRoleToPartsAndValidateSendMessageRequest(newParts);\n}\n/**\n * When multiple Part types (i.e. FunctionResponsePart and TextPart) are\n * passed in a single Part array, we may need to assign different roles to each\n * part. Currently only FunctionResponsePart requires a role other than 'user'.\n * @private\n * @param parts Array of parts to pass to the model\n * @returns Array of content items\n */\nfunction assignRoleToPartsAndValidateSendMessageRequest(parts) {\n    const userContent = { role: \"user\", parts: [] };\n    const functionContent = { role: \"function\", parts: [] };\n    let hasUserContent = false;\n    let hasFunctionContent = false;\n    for (const part of parts) {\n        if (\"functionResponse\" in part) {\n            functionContent.parts.push(part);\n            hasFunctionContent = true;\n        }\n        else {\n            userContent.parts.push(part);\n            hasUserContent = true;\n        }\n    }\n    if (hasUserContent && hasFunctionContent) {\n        throw new GoogleGenerativeAIError(\"Within a single message, FunctionResponse cannot be mixed with other type of part in the request for sending chat message.\");\n    }\n    if (!hasUserContent && !hasFunctionContent) {\n        throw new GoogleGenerativeAIError(\"No content is provided for sending chat message.\");\n    }\n    if (hasUserContent) {\n        return userContent;\n    }\n    return functionContent;\n}\nfunction formatCountTokensInput(params, modelParams) {\n    var _a;\n    let formattedGenerateContentRequest = {\n        model: modelParams === null || modelParams === void 0 ? void 0 : modelParams.model,\n        generationConfig: modelParams === null || modelParams === void 0 ? void 0 : modelParams.generationConfig,\n        safetySettings: modelParams === null || modelParams === void 0 ? void 0 : modelParams.safetySettings,\n        tools: modelParams === null || modelParams === void 0 ? void 0 : modelParams.tools,\n        toolConfig: modelParams === null || modelParams === void 0 ? void 0 : modelParams.toolConfig,\n        systemInstruction: modelParams === null || modelParams === void 0 ? void 0 : modelParams.systemInstruction,\n        cachedContent: (_a = modelParams === null || modelParams === void 0 ? void 0 : modelParams.cachedContent) === null || _a === void 0 ? void 0 : _a.name,\n        contents: [],\n    };\n    const containsGenerateContentRequest = params.generateContentRequest != null;\n    if (params.contents) {\n        if (containsGenerateContentRequest) {\n            throw new GoogleGenerativeAIRequestInputError(\"CountTokensRequest must have one of contents or generateContentRequest, not both.\");\n        }\n        formattedGenerateContentRequest.contents = params.contents;\n    }\n    else if (containsGenerateContentRequest) {\n        formattedGenerateContentRequest = Object.assign(Object.assign({}, formattedGenerateContentRequest), params.generateContentRequest);\n    }\n    else {\n        // Array or string\n        const content = formatNewContent(params);\n        formattedGenerateContentRequest.contents = [content];\n    }\n    return { generateContentRequest: formattedGenerateContentRequest };\n}\nfunction formatGenerateContentInput(params) {\n    let formattedRequest;\n    if (params.contents) {\n        formattedRequest = params;\n    }\n    else {\n        // Array or string\n        const content = formatNewContent(params);\n        formattedRequest = { contents: [content] };\n    }\n    if (params.systemInstruction) {\n        formattedRequest.systemInstruction = formatSystemInstruction(params.systemInstruction);\n    }\n    return formattedRequest;\n}\nfunction formatEmbedContentInput(params) {\n    if (typeof params === \"string\" || Array.isArray(params)) {\n        const content = formatNewContent(params);\n        return { content };\n    }\n    return params;\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n// https://ai.google.dev/api/rest/v1beta/Content#part\nconst VALID_PART_FIELDS = [\n    \"text\",\n    \"inlineData\",\n    \"functionCall\",\n    \"functionResponse\",\n    \"executableCode\",\n    \"codeExecutionResult\",\n];\nconst VALID_PARTS_PER_ROLE = {\n    user: [\"text\", \"inlineData\"],\n    function: [\"functionResponse\"],\n    model: [\"text\", \"functionCall\", \"executableCode\", \"codeExecutionResult\"],\n    // System instructions shouldn't be in history anyway.\n    system: [\"text\"],\n};\nfunction validateChatHistory(history) {\n    let prevContent = false;\n    for (const currContent of history) {\n        const { role, parts } = currContent;\n        if (!prevContent && role !== \"user\") {\n            throw new GoogleGenerativeAIError(`First content should be with role 'user', got ${role}`);\n        }\n        if (!POSSIBLE_ROLES.includes(role)) {\n            throw new GoogleGenerativeAIError(`Each item should include role field. Got ${role} but valid roles are: ${JSON.stringify(POSSIBLE_ROLES)}`);\n        }\n        if (!Array.isArray(parts)) {\n            throw new GoogleGenerativeAIError(\"Content should have 'parts' property with an array of Parts\");\n        }\n        if (parts.length === 0) {\n            throw new GoogleGenerativeAIError(\"Each Content should have at least one part\");\n        }\n        const countFields = {\n            text: 0,\n            inlineData: 0,\n            functionCall: 0,\n            functionResponse: 0,\n            fileData: 0,\n            executableCode: 0,\n            codeExecutionResult: 0,\n        };\n        for (const part of parts) {\n            for (const key of VALID_PART_FIELDS) {\n                if (key in part) {\n                    countFields[key] += 1;\n                }\n            }\n        }\n        const validParts = VALID_PARTS_PER_ROLE[role];\n        for (const key of VALID_PART_FIELDS) {\n            if (!validParts.includes(key) && countFields[key] > 0) {\n                throw new GoogleGenerativeAIError(`Content with role '${role}' can't contain '${key}' part`);\n            }\n        }\n        prevContent = true;\n    }\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Do not log a message for this error.\n */\nconst SILENT_ERROR = \"SILENT_ERROR\";\n/**\n * ChatSession class that enables sending chat messages and stores\n * history of sent and received messages so far.\n *\n * @public\n */\nclass ChatSession {\n    constructor(apiKey, model, params, _requestOptions = {}) {\n        this.model = model;\n        this.params = params;\n        this._requestOptions = _requestOptions;\n        this._history = [];\n        this._sendPromise = Promise.resolve();\n        this._apiKey = apiKey;\n        if (params === null || params === void 0 ? void 0 : params.history) {\n            validateChatHistory(params.history);\n            this._history = params.history;\n        }\n    }\n    /**\n     * Gets the chat history so far. Blocked prompts are not added to history.\n     * Blocked candidates are not added to history, nor are the prompts that\n     * generated them.\n     */\n    async getHistory() {\n        await this._sendPromise;\n        return this._history;\n    }\n    /**\n     * Sends a chat message and receives a non-streaming\n     * {@link GenerateContentResult}.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async sendMessage(request, requestOptions = {}) {\n        var _a, _b, _c, _d, _e, _f;\n        await this._sendPromise;\n        const newContent = formatNewContent(request);\n        const generateContentRequest = {\n            safetySettings: (_a = this.params) === null || _a === void 0 ? void 0 : _a.safetySettings,\n            generationConfig: (_b = this.params) === null || _b === void 0 ? void 0 : _b.generationConfig,\n            tools: (_c = this.params) === null || _c === void 0 ? void 0 : _c.tools,\n            toolConfig: (_d = this.params) === null || _d === void 0 ? void 0 : _d.toolConfig,\n            systemInstruction: (_e = this.params) === null || _e === void 0 ? void 0 : _e.systemInstruction,\n            cachedContent: (_f = this.params) === null || _f === void 0 ? void 0 : _f.cachedContent,\n            contents: [...this._history, newContent],\n        };\n        const chatSessionRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        let finalResult;\n        // Add onto the chain.\n        this._sendPromise = this._sendPromise\n            .then(() => generateContent(this._apiKey, this.model, generateContentRequest, chatSessionRequestOptions))\n            .then((result) => {\n            var _a;\n            if (result.response.candidates &&\n                result.response.candidates.length > 0) {\n                this._history.push(newContent);\n                const responseContent = Object.assign({ parts: [], \n                    // Response seems to come back without a role set.\n                    role: \"model\" }, (_a = result.response.candidates) === null || _a === void 0 ? void 0 : _a[0].content);\n                this._history.push(responseContent);\n            }\n            else {\n                const blockErrorMessage = formatBlockErrorMessage(result.response);\n                if (blockErrorMessage) {\n                    console.warn(`sendMessage() was unsuccessful. ${blockErrorMessage}. Inspect response object for details.`);\n                }\n            }\n            finalResult = result;\n        });\n        await this._sendPromise;\n        return finalResult;\n    }\n    /**\n     * Sends a chat message and receives the response as a\n     * {@link GenerateContentStreamResult} containing an iterable stream\n     * and a response promise.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async sendMessageStream(request, requestOptions = {}) {\n        var _a, _b, _c, _d, _e, _f;\n        await this._sendPromise;\n        const newContent = formatNewContent(request);\n        const generateContentRequest = {\n            safetySettings: (_a = this.params) === null || _a === void 0 ? void 0 : _a.safetySettings,\n            generationConfig: (_b = this.params) === null || _b === void 0 ? void 0 : _b.generationConfig,\n            tools: (_c = this.params) === null || _c === void 0 ? void 0 : _c.tools,\n            toolConfig: (_d = this.params) === null || _d === void 0 ? void 0 : _d.toolConfig,\n            systemInstruction: (_e = this.params) === null || _e === void 0 ? void 0 : _e.systemInstruction,\n            cachedContent: (_f = this.params) === null || _f === void 0 ? void 0 : _f.cachedContent,\n            contents: [...this._history, newContent],\n        };\n        const chatSessionRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        const streamPromise = generateContentStream(this._apiKey, this.model, generateContentRequest, chatSessionRequestOptions);\n        // Add onto the chain.\n        this._sendPromise = this._sendPromise\n            .then(() => streamPromise)\n            // This must be handled to avoid unhandled rejection, but jump\n            // to the final catch block with a label to not log this error.\n            .catch((_ignored) => {\n            throw new Error(SILENT_ERROR);\n        })\n            .then((streamResult) => streamResult.response)\n            .then((response) => {\n            if (response.candidates && response.candidates.length > 0) {\n                this._history.push(newContent);\n                const responseContent = Object.assign({}, response.candidates[0].content);\n                // Response seems to come back without a role set.\n                if (!responseContent.role) {\n                    responseContent.role = \"model\";\n                }\n                this._history.push(responseContent);\n            }\n            else {\n                const blockErrorMessage = formatBlockErrorMessage(response);\n                if (blockErrorMessage) {\n                    console.warn(`sendMessageStream() was unsuccessful. ${blockErrorMessage}. Inspect response object for details.`);\n                }\n            }\n        })\n            .catch((e) => {\n            // Errors in streamPromise are already catchable by the user as\n            // streamPromise is returned.\n            // Avoid duplicating the error message in logs.\n            if (e.message !== SILENT_ERROR) {\n                // Users do not have access to _sendPromise to catch errors\n                // downstream from streamPromise, so they should not throw.\n                console.error(e);\n            }\n        });\n        return streamPromise;\n    }\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nasync function countTokens(apiKey, model, params, singleRequestOptions) {\n    const response = await makeModelRequest(model, Task.COUNT_TOKENS, apiKey, false, JSON.stringify(params), singleRequestOptions);\n    return response.json();\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nasync function embedContent(apiKey, model, params, requestOptions) {\n    const response = await makeModelRequest(model, Task.EMBED_CONTENT, apiKey, false, JSON.stringify(params), requestOptions);\n    return response.json();\n}\nasync function batchEmbedContents(apiKey, model, params, requestOptions) {\n    const requestsWithModel = params.requests.map((request) => {\n        return Object.assign(Object.assign({}, request), { model });\n    });\n    const response = await makeModelRequest(model, Task.BATCH_EMBED_CONTENTS, apiKey, false, JSON.stringify({ requests: requestsWithModel }), requestOptions);\n    return response.json();\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Class for generative model APIs.\n * @public\n */\nclass GenerativeModel {\n    constructor(apiKey, modelParams, _requestOptions = {}) {\n        this.apiKey = apiKey;\n        this._requestOptions = _requestOptions;\n        if (modelParams.model.includes(\"/\")) {\n            // Models may be named \"models/model-name\" or \"tunedModels/model-name\"\n            this.model = modelParams.model;\n        }\n        else {\n            // If path is not included, assume it's a non-tuned model.\n            this.model = `models/${modelParams.model}`;\n        }\n        this.generationConfig = modelParams.generationConfig || {};\n        this.safetySettings = modelParams.safetySettings || [];\n        this.tools = modelParams.tools;\n        this.toolConfig = modelParams.toolConfig;\n        this.systemInstruction = formatSystemInstruction(modelParams.systemInstruction);\n        this.cachedContent = modelParams.cachedContent;\n    }\n    /**\n     * Makes a single non-streaming call to the model\n     * and returns an object containing a single {@link GenerateContentResponse}.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async generateContent(request, requestOptions = {}) {\n        var _a;\n        const formattedParams = formatGenerateContentInput(request);\n        const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        return generateContent(this.apiKey, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings, tools: this.tools, toolConfig: this.toolConfig, systemInstruction: this.systemInstruction, cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name }, formattedParams), generativeModelRequestOptions);\n    }\n    /**\n     * Makes a single streaming call to the model and returns an object\n     * containing an iterable stream that iterates over all chunks in the\n     * streaming response as well as a promise that returns the final\n     * aggregated response.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async generateContentStream(request, requestOptions = {}) {\n        var _a;\n        const formattedParams = formatGenerateContentInput(request);\n        const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        return generateContentStream(this.apiKey, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings, tools: this.tools, toolConfig: this.toolConfig, systemInstruction: this.systemInstruction, cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name }, formattedParams), generativeModelRequestOptions);\n    }\n    /**\n     * Gets a new {@link ChatSession} instance which can be used for\n     * multi-turn chats.\n     */\n    startChat(startChatParams) {\n        var _a;\n        return new ChatSession(this.apiKey, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings, tools: this.tools, toolConfig: this.toolConfig, systemInstruction: this.systemInstruction, cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name }, startChatParams), this._requestOptions);\n    }\n    /**\n     * Counts the tokens in the provided request.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async countTokens(request, requestOptions = {}) {\n        const formattedParams = formatCountTokensInput(request, {\n            model: this.model,\n            generationConfig: this.generationConfig,\n            safetySettings: this.safetySettings,\n            tools: this.tools,\n            toolConfig: this.toolConfig,\n            systemInstruction: this.systemInstruction,\n            cachedContent: this.cachedContent,\n        });\n        const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        return countTokens(this.apiKey, this.model, formattedParams, generativeModelRequestOptions);\n    }\n    /**\n     * Embeds the provided content.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async embedContent(request, requestOptions = {}) {\n        const formattedParams = formatEmbedContentInput(request);\n        const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        return embedContent(this.apiKey, this.model, formattedParams, generativeModelRequestOptions);\n    }\n    /**\n     * Embeds an array of {@link EmbedContentRequest}s.\n     *\n     * Fields set in the optional {@link SingleRequestOptions} parameter will\n     * take precedence over the {@link RequestOptions} values provided to\n     * {@link GoogleGenerativeAI.getGenerativeModel }.\n     */\n    async batchEmbedContents(batchEmbedContentRequest, requestOptions = {}) {\n        const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);\n        return batchEmbedContents(this.apiKey, this.model, batchEmbedContentRequest, generativeModelRequestOptions);\n    }\n}\n\n/**\n * @license\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Top-level class for this SDK\n * @public\n */\nclass GoogleGenerativeAI {\n    constructor(apiKey) {\n        this.apiKey = apiKey;\n    }\n    /**\n     * Gets a {@link GenerativeModel} instance for the provided model name.\n     */\n    getGenerativeModel(modelParams, requestOptions) {\n        if (!modelParams.model) {\n            throw new GoogleGenerativeAIError(`Must provide a model name. ` +\n                `Example: genai.getGenerativeModel({ model: 'my-model-name' })`);\n        }\n        return new GenerativeModel(this.apiKey, modelParams, requestOptions);\n    }\n    /**\n     * Creates a {@link GenerativeModel} instance from provided content cache.\n     */\n    getGenerativeModelFromCachedContent(cachedContent, modelParams, requestOptions) {\n        if (!cachedContent.name) {\n            throw new GoogleGenerativeAIRequestInputError(\"Cached content must contain a `name` field.\");\n        }\n        if (!cachedContent.model) {\n            throw new GoogleGenerativeAIRequestInputError(\"Cached content must contain a `model` field.\");\n        }\n        /**\n         * Not checking tools and toolConfig for now as it would require a deep\n         * equality comparison and isn't likely to be a common case.\n         */\n        const disallowedDuplicates = [\"model\", \"systemInstruction\"];\n        for (const key of disallowedDuplicates) {\n            if ((modelParams === null || modelParams === void 0 ? void 0 : modelParams[key]) &&\n                cachedContent[key] &&\n                (modelParams === null || modelParams === void 0 ? void 0 : modelParams[key]) !== cachedContent[key]) {\n                if (key === \"model\") {\n                    const modelParamsComp = modelParams.model.startsWith(\"models/\")\n                        ? modelParams.model.replace(\"models/\", \"\")\n                        : modelParams.model;\n                    const cachedContentComp = cachedContent.model.startsWith(\"models/\")\n                        ? cachedContent.model.replace(\"models/\", \"\")\n                        : cachedContent.model;\n                    if (modelParamsComp === cachedContentComp) {\n                        continue;\n                    }\n                }\n                throw new GoogleGenerativeAIRequestInputError(`Different value for \"${key}\" specified in modelParams` +\n                    ` (${modelParams[key]}) and cachedContent (${cachedContent[key]})`);\n            }\n        }\n        const modelParamsFromCache = Object.assign(Object.assign({}, modelParams), { model: cachedContent.model, tools: cachedContent.tools, toolConfig: cachedContent.toolConfig, systemInstruction: cachedContent.systemInstruction, cachedContent });\n        return new GenerativeModel(this.apiKey, modelParamsFromCache, requestOptions);\n    }\n}\n\nexport { BlockReason, ChatSession, DynamicRetrievalMode, ExecutableCodeLanguage, FinishReason, FunctionCallingMode, GenerativeModel, GoogleGenerativeAI, GoogleGenerativeAIError, GoogleGenerativeAIFetchError, GoogleGenerativeAIRequestInputError, GoogleGenerativeAIResponseError, HarmBlockThreshold, HarmCategory, HarmProbability, Outcome, POSSIBLE_ROLES, SchemaType, TaskType };\n//# sourceMappingURL=index.mjs.map\n", "/* eslint-disable @typescript-eslint/no-unused-vars */\nimport { zodToJsonSchema } from \"zod-to-json-schema\";\nexport function removeAdditionalProperties(\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nobj) {\n    if (typeof obj === \"object\" && obj !== null) {\n        const newObj = { ...obj };\n        if (\"additionalProperties\" in newObj) {\n            delete newObj.additionalProperties;\n        }\n        if (\"$schema\" in newObj) {\n            delete newObj.$schema;\n        }\n        for (const key in newObj) {\n            if (key in newObj) {\n                if (Array.isArray(newObj[key])) {\n                    newObj[key] = newObj[key].map(removeAdditionalProperties);\n                }\n                else if (typeof newObj[key] === \"object\" && newObj[key] !== null) {\n                    newObj[key] = removeAdditionalProperties(newObj[key]);\n                }\n            }\n        }\n        return newObj;\n    }\n    return obj;\n}\nexport function zodToGenerativeAIParameters(\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nzodObj) {\n    // GenerativeAI doesn't accept either the $schema or additionalProperties\n    // attributes, so we need to explicitly remove them.\n    const jsonSchema = removeAdditionalProperties(zodToJsonSchema(zodObj));\n    const { $schema, ...rest } = jsonSchema;\n    return rest;\n}\nexport function jsonSchemaToGeminiParameters(\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nschema) {\n    // Gemini doesn't accept either the $schema or additionalProperties\n    // attributes, so we need to explicitly remove them.\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const jsonSchema = removeAdditionalProperties(schema);\n    const { $schema, ...rest } = jsonSchema;\n    return rest;\n}\n", "import { AIMessage, AIMessageChunk, ChatMessage, isBaseMessage, } from \"@langchain/core/messages\";\nimport { ChatGenerationChunk, } from \"@langchain/core/outputs\";\nimport { isLangChainTool } from \"@langchain/core/utils/function_calling\";\nimport { isOpenAITool } from \"@langchain/core/language_models/base\";\nimport { jsonSchemaToGeminiParameters, zodToGenerativeAIParameters, } from \"./zod_to_genai_parameters.js\";\nexport function getMessageAuthor(message) {\n    const type = message._getType();\n    if (ChatMessage.isInstance(message)) {\n        return message.role;\n    }\n    if (type === \"tool\") {\n        return type;\n    }\n    return message.name ?? type;\n}\n/**\n * Maps a message type to a Google Generative AI chat author.\n * @param message The message to map.\n * @param model The model to use for mapping.\n * @returns The message type mapped to a Google Generative AI chat author.\n */\nexport function convertAuthorToRole(author) {\n    switch (author) {\n        /**\n         *  Note: Gemini currently is not supporting system messages\n         *  we will convert them to human messages and merge with following\n         * */\n        case \"ai\":\n        case \"model\": // getMessageAuthor returns message.name. code ex.: return message.name ?? type;\n            return \"model\";\n        case \"system\":\n            return \"system\";\n        case \"human\":\n            return \"user\";\n        case \"tool\":\n        case \"function\":\n            return \"function\";\n        default:\n            throw new Error(`Unknown / unsupported author: ${author}`);\n    }\n}\nfunction messageContentMedia(content) {\n    if (\"mimeType\" in content && \"data\" in content) {\n        return {\n            inlineData: {\n                mimeType: content.mimeType,\n                data: content.data,\n            },\n        };\n    }\n    if (\"mimeType\" in content && \"fileUri\" in content) {\n        return {\n            fileData: {\n                mimeType: content.mimeType,\n                fileUri: content.fileUri,\n            },\n        };\n    }\n    throw new Error(\"Invalid media content\");\n}\nexport function convertMessageContentToParts(message, isMultimodalModel) {\n    if (typeof message.content === \"string\" && message.content !== \"\") {\n        return [{ text: message.content }];\n    }\n    let functionCalls = [];\n    let functionResponses = [];\n    let messageParts = [];\n    if (\"tool_calls\" in message &&\n        Array.isArray(message.tool_calls) &&\n        message.tool_calls.length > 0) {\n        functionCalls = message.tool_calls.map((tc) => ({\n            functionCall: {\n                name: tc.name,\n                args: tc.args,\n            },\n        }));\n    }\n    else if (message.getType() === \"tool\" && message.name && message.content) {\n        functionResponses = [\n            {\n                functionResponse: {\n                    name: message.name,\n                    response: message.content,\n                },\n            },\n        ];\n    }\n    else if (Array.isArray(message.content)) {\n        messageParts = message.content.map((c) => {\n            if (c.type === \"text\") {\n                return {\n                    text: c.text,\n                };\n            }\n            else if (c.type === \"executableCode\") {\n                return {\n                    executableCode: c.executableCode,\n                };\n            }\n            else if (c.type === \"codeExecutionResult\") {\n                return {\n                    codeExecutionResult: c.codeExecutionResult,\n                };\n            }\n            if (c.type === \"image_url\") {\n                if (!isMultimodalModel) {\n                    throw new Error(`This model does not support images`);\n                }\n                let source;\n                if (typeof c.image_url === \"string\") {\n                    source = c.image_url;\n                }\n                else if (typeof c.image_url === \"object\" && \"url\" in c.image_url) {\n                    source = c.image_url.url;\n                }\n                else {\n                    throw new Error(\"Please provide image as base64 encoded data URL\");\n                }\n                const [dm, data] = source.split(\",\");\n                if (!dm.startsWith(\"data:\")) {\n                    throw new Error(\"Please provide image as base64 encoded data URL\");\n                }\n                const [mimeType, encoding] = dm.replace(/^data:/, \"\").split(\";\");\n                if (encoding !== \"base64\") {\n                    throw new Error(\"Please provide image as base64 encoded data URL\");\n                }\n                return {\n                    inlineData: {\n                        data,\n                        mimeType,\n                    },\n                };\n            }\n            else if (c.type === \"media\") {\n                return messageContentMedia(c);\n            }\n            else if (c.type === \"tool_use\") {\n                return {\n                    functionCall: {\n                        name: c.name,\n                        args: c.input,\n                    },\n                };\n            }\n            else if (c.type?.includes(\"/\") &&\n                // Ensure it's a single slash.\n                c.type.split(\"/\").length === 2 &&\n                \"data\" in c &&\n                typeof c.data === \"string\") {\n                return {\n                    inlineData: {\n                        mimeType: c.type,\n                        data: c.data,\n                    },\n                };\n            }\n            throw new Error(`Unknown content type ${c.type}`);\n        });\n    }\n    return [...messageParts, ...functionCalls, ...functionResponses];\n}\nexport function convertBaseMessagesToContent(messages, isMultimodalModel, convertSystemMessageToHumanContent = false) {\n    return messages.reduce((acc, message, index) => {\n        if (!isBaseMessage(message)) {\n            throw new Error(\"Unsupported message input\");\n        }\n        const author = getMessageAuthor(message);\n        if (author === \"system\" && index !== 0) {\n            throw new Error(\"System message should be the first one\");\n        }\n        const role = convertAuthorToRole(author);\n        const prevContent = acc.content[acc.content.length];\n        if (!acc.mergeWithPreviousContent &&\n            prevContent &&\n            prevContent.role === role) {\n            throw new Error(\"Google Generative AI requires alternate messages between authors\");\n        }\n        const parts = convertMessageContentToParts(message, isMultimodalModel);\n        if (acc.mergeWithPreviousContent) {\n            const prevContent = acc.content[acc.content.length - 1];\n            if (!prevContent) {\n                throw new Error(\"There was a problem parsing your system message. Please try a prompt without one.\");\n            }\n            prevContent.parts.push(...parts);\n            return {\n                mergeWithPreviousContent: false,\n                content: acc.content,\n            };\n        }\n        let actualRole = role;\n        if (actualRole === \"function\" ||\n            (actualRole === \"system\" && !convertSystemMessageToHumanContent)) {\n            // GenerativeAI API will throw an error if the role is not \"user\" or \"model.\"\n            actualRole = \"user\";\n        }\n        const content = {\n            role: actualRole,\n            parts,\n        };\n        return {\n            mergeWithPreviousContent: author === \"system\" && !convertSystemMessageToHumanContent,\n            content: [...acc.content, content],\n        };\n    }, { content: [], mergeWithPreviousContent: false }).content;\n}\nexport function mapGenerateContentResultToChatResult(response, extra) {\n    // if rejected or error, return empty generations with reason in filters\n    if (!response.candidates ||\n        response.candidates.length === 0 ||\n        !response.candidates[0]) {\n        return {\n            generations: [],\n            llmOutput: {\n                filters: response.promptFeedback,\n            },\n        };\n    }\n    const functionCalls = response.functionCalls();\n    const [candidate] = response.candidates;\n    const { content: candidateContent, ...generationInfo } = candidate;\n    let content;\n    if (candidateContent?.parts.length === 1 && candidateContent.parts[0].text) {\n        content = candidateContent.parts[0].text;\n    }\n    else {\n        content = candidateContent.parts.map((p) => {\n            if (\"text\" in p) {\n                return {\n                    type: \"text\",\n                    text: p.text,\n                };\n            }\n            else if (\"executableCode\" in p) {\n                return {\n                    type: \"executableCode\",\n                    executableCode: p.executableCode,\n                };\n            }\n            else if (\"codeExecutionResult\" in p) {\n                return {\n                    type: \"codeExecutionResult\",\n                    codeExecutionResult: p.codeExecutionResult,\n                };\n            }\n            return p;\n        });\n    }\n    let text = \"\";\n    if (typeof content === \"string\") {\n        text = content;\n    }\n    else if (\"text\" in content[0]) {\n        text = content[0].text;\n    }\n    const generation = {\n        text,\n        message: new AIMessage({\n            content,\n            tool_calls: functionCalls?.map((fc) => ({\n                ...fc,\n                type: \"tool_call\",\n            })),\n            additional_kwargs: {\n                ...generationInfo,\n            },\n            usage_metadata: extra?.usageMetadata,\n        }),\n        generationInfo,\n    };\n    return {\n        generations: [generation],\n        llmOutput: {\n            tokenUsage: {\n                promptTokens: extra?.usageMetadata?.input_tokens,\n                completionTokens: extra?.usageMetadata?.output_tokens,\n                totalTokens: extra?.usageMetadata?.total_tokens,\n            },\n        },\n    };\n}\nexport function convertResponseContentToChatGenerationChunk(response, extra) {\n    if (!response.candidates || response.candidates.length === 0) {\n        return null;\n    }\n    const functionCalls = response.functionCalls();\n    const [candidate] = response.candidates;\n    const { content: candidateContent, ...generationInfo } = candidate;\n    let content;\n    // Checks if some parts do not have text. If false, it means that the content is a string.\n    if (candidateContent?.parts &&\n        candidateContent.parts.every((p) => \"text\" in p)) {\n        content = candidateContent.parts.map((p) => p.text).join(\"\");\n    }\n    else if (candidateContent.parts) {\n        content = candidateContent.parts.map((p) => {\n            if (\"text\" in p) {\n                return {\n                    type: \"text\",\n                    text: p.text,\n                };\n            }\n            else if (\"executableCode\" in p) {\n                return {\n                    type: \"executableCode\",\n                    executableCode: p.executableCode,\n                };\n            }\n            else if (\"codeExecutionResult\" in p) {\n                return {\n                    type: \"codeExecutionResult\",\n                    codeExecutionResult: p.codeExecutionResult,\n                };\n            }\n            return p;\n        });\n    }\n    let text = \"\";\n    if (content && typeof content === \"string\") {\n        text = content;\n    }\n    else if (content && typeof content === \"object\" && \"text\" in content[0]) {\n        text = content[0].text;\n    }\n    const toolCallChunks = [];\n    if (functionCalls) {\n        toolCallChunks.push(...functionCalls.map((fc) => ({\n            ...fc,\n            args: JSON.stringify(fc.args),\n            index: extra.index,\n            type: \"tool_call_chunk\",\n        })));\n    }\n    return new ChatGenerationChunk({\n        text,\n        message: new AIMessageChunk({\n            content: content || \"\",\n            name: !candidateContent ? undefined : candidateContent.role,\n            tool_call_chunks: toolCallChunks,\n            // Each chunk can have unique \"generationInfo\", and merging strategy is unclear,\n            // so leave blank for now.\n            additional_kwargs: {},\n            usage_metadata: extra.usageMetadata,\n        }),\n        generationInfo,\n    });\n}\nexport function convertToGenerativeAITools(tools) {\n    if (tools.every((tool) => \"functionDeclarations\" in tool &&\n        Array.isArray(tool.functionDeclarations))) {\n        return tools;\n    }\n    return [\n        {\n            functionDeclarations: tools.map((tool) => {\n                if (isLangChainTool(tool)) {\n                    const jsonSchema = zodToGenerativeAIParameters(tool.schema);\n                    return {\n                        name: tool.name,\n                        description: tool.description,\n                        parameters: jsonSchema,\n                    };\n                }\n                if (isOpenAITool(tool)) {\n                    return {\n                        name: tool.function.name,\n                        description: tool.function.description ?? `A function available to call.`,\n                        parameters: jsonSchemaToGeminiParameters(tool.function.parameters),\n                    };\n                }\n                return tool;\n            }),\n        },\n    ];\n}\n", "import { BaseLLMOutputParser, OutputParserException, } from \"@langchain/core/output_parsers\";\nexport class GoogleGenerativeAIToolsOutputParser extends BaseLLMOutputParser {\n    static lc_name() {\n        return \"GoogleGenerativeAIToolsOutputParser\";\n    }\n    constructor(params) {\n        super(params);\n        Object.defineProperty(this, \"lc_namespace\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: [\"langchain\", \"google_genai\", \"output_parsers\"]\n        });\n        Object.defineProperty(this, \"returnId\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        /** The type of tool calls to return. */\n        Object.defineProperty(this, \"keyName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        /** Whether to return only the first tool call. */\n        Object.defineProperty(this, \"returnSingle\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"zodSchema\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.keyName = params.keyName;\n        this.returnSingle = params.returnSingle ?? this.returnSingle;\n        this.zodSchema = params.zodSchema;\n    }\n    async _validateResult(result) {\n        if (this.zodSchema === undefined) {\n            return result;\n        }\n        const zodParsedResult = await this.zodSchema.safeParseAsync(result);\n        if (zodParsedResult.success) {\n            return zodParsedResult.data;\n        }\n        else {\n            throw new OutputParserException(`Failed to parse. Text: \"${JSON.stringify(result, null, 2)}\". Error: ${JSON.stringify(zodParsedResult.error.errors)}`, JSON.stringify(result, null, 2));\n        }\n    }\n    async parseResult(generations) {\n        const tools = generations.flatMap((generation) => {\n            const { message } = generation;\n            if (!(\"tool_calls\" in message) || !Array.isArray(message.tool_calls)) {\n                return [];\n            }\n            return message.tool_calls;\n        });\n        if (tools[0] === undefined) {\n            throw new Error(\"No parseable tool calls provided to GoogleGenerativeAIToolsOutputParser.\");\n        }\n        const [tool] = tools;\n        const validatedResult = await this._validateResult(tool.args);\n        return validatedResult;\n    }\n}\n", "import { FunctionCallingMode, } from \"@google/generative-ai\";\nimport { isLangChainTool } from \"@langchain/core/utils/function_calling\";\nimport { isOpenAITool, } from \"@langchain/core/language_models/base\";\nimport { convertToGenerativeAITools } from \"./common.js\";\nimport { removeAdditionalProperties } from \"./zod_to_genai_parameters.js\";\nexport function convertToolsToGenAI(tools, extra) {\n    // Extract function declaration processing to a separate function\n    const genAITools = processTools(tools);\n    // Simplify tool config creation\n    const toolConfig = createToolConfig(genAITools, extra);\n    return { tools: genAITools, toolConfig };\n}\nfunction processTools(tools) {\n    let functionDeclarationTools = [];\n    const genAITools = [];\n    tools.forEach((tool) => {\n        if (isLangChainTool(tool)) {\n            const [convertedTool] = convertToGenerativeAITools([\n                tool,\n            ]);\n            if (convertedTool.functionDeclarations) {\n                functionDeclarationTools.push(...convertedTool.functionDeclarations);\n            }\n        }\n        else if (isOpenAITool(tool)) {\n            const { functionDeclarations } = convertOpenAIToolToGenAI(tool);\n            if (functionDeclarations) {\n                functionDeclarationTools.push(...functionDeclarations);\n            }\n            else {\n                throw new Error(\"Failed to convert OpenAI structured tool to GenerativeAI tool\");\n            }\n        }\n        else {\n            genAITools.push(tool);\n        }\n    });\n    const genAIFunctionDeclaration = genAITools.find((t) => \"functionDeclarations\" in t);\n    if (genAIFunctionDeclaration) {\n        return genAITools.map((tool) => {\n            if (functionDeclarationTools?.length > 0 &&\n                \"functionDeclarations\" in tool) {\n                const newTool = {\n                    functionDeclarations: [\n                        ...(tool.functionDeclarations || []),\n                        ...functionDeclarationTools,\n                    ],\n                };\n                // Clear the functionDeclarationTools array so it is not passed again\n                functionDeclarationTools = [];\n                return newTool;\n            }\n            return tool;\n        });\n    }\n    return [\n        ...genAITools,\n        ...(functionDeclarationTools.length > 0\n            ? [\n                {\n                    functionDeclarations: functionDeclarationTools,\n                },\n            ]\n            : []),\n    ];\n}\nfunction convertOpenAIToolToGenAI(tool) {\n    return {\n        functionDeclarations: [\n            {\n                name: tool.function.name,\n                description: tool.function.description,\n                parameters: removeAdditionalProperties(tool.function.parameters),\n            },\n        ],\n    };\n}\nfunction createToolConfig(genAITools, extra) {\n    if (!genAITools.length || !extra)\n        return undefined;\n    const { toolChoice, allowedFunctionNames } = extra;\n    const modeMap = {\n        any: FunctionCallingMode.ANY,\n        auto: FunctionCallingMode.AUTO,\n        none: FunctionCallingMode.NONE,\n    };\n    if (toolChoice && [\"any\", \"auto\", \"none\"].includes(toolChoice)) {\n        return {\n            functionCallingConfig: {\n                mode: modeMap[toolChoice] ?? \"MODE_UNSPECIFIED\",\n                allowedFunctionNames,\n            },\n        };\n    }\n    if (typeof toolChoice === \"string\" || allowedFunctionNames) {\n        return {\n            functionCallingConfig: {\n                mode: FunctionCallingMode.ANY,\n                allowedFunctionNames: [\n                    ...(allowedFunctionNames ?? []),\n                    ...(toolChoice && typeof toolChoice === \"string\" ? [toolChoice] : []),\n                ],\n            },\n        };\n    }\n    return undefined;\n}\n", "import { GoogleGenerativeAI as GenerativeAI, } from \"@google/generative-ai\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport { BaseChatModel, } from \"@langchain/core/language_models/chat_models\";\nimport { RunnablePassthrough, RunnableSequence, } from \"@langchain/core/runnables\";\nimport { isZodSchema } from \"@langchain/core/utils/types\";\nimport { zodToGenerativeAIParameters } from \"./utils/zod_to_genai_parameters.js\";\nimport { convertBaseMessagesToContent, convertResponseContentToChatGenerationChunk, mapGenerateContentResultToChatResult, } from \"./utils/common.js\";\nimport { GoogleGenerativeAIToolsOutputParser } from \"./output_parsers.js\";\nimport { convertToolsToGenAI } from \"./utils/tools.js\";\n/**\n * Google Generative AI chat model integration.\n *\n * Setup:\n * Install `@langchain/google-genai` and set an environment variable named `GOOGLE_API_KEY`.\n *\n * ```bash\n * npm install @langchain/google-genai\n * export GOOGLE_API_KEY=\"your-api-key\"\n * ```\n *\n * ## [Constructor args](https://api.js.langchain.com/classes/langchain_google_genai.ChatGoogleGenerativeAI.html#constructor)\n *\n * ## [Runtime args](https://api.js.langchain.com/interfaces/langchain_google_genai.GoogleGenerativeAIChatCallOptions.html)\n *\n * Runtime args can be passed as the second argument to any of the base runnable methods `.invoke`. `.stream`, `.batch`, etc.\n * They can also be passed via `.bind`, or the second arg in `.bindTools`, like shown in the examples below:\n *\n * ```typescript\n * // When calling `.bind`, call options should be passed via the first argument\n * const llmWithArgsBound = llm.bind({\n *   stop: [\"\\n\"],\n *   tools: [...],\n * });\n *\n * // When calling `.bindTools`, call options should be passed via the second argument\n * const llmWithTools = llm.bindTools(\n *   [...],\n *   {\n *     stop: [\"\\n\"],\n *   }\n * );\n * ```\n *\n * ## Examples\n *\n * <details open>\n * <summary><strong>Instantiate</strong></summary>\n *\n * ```typescript\n * import { ChatGoogleGenerativeAI } from '@langchain/google-genai';\n *\n * const llm = new ChatGoogleGenerativeAI({\n *   model: \"gemini-1.5-flash\",\n *   temperature: 0,\n *   maxRetries: 2,\n *   // apiKey: \"...\",\n *   // other params...\n * });\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Invoking</strong></summary>\n *\n * ```typescript\n * const input = `Translate \"I love programming\" into French.`;\n *\n * // Models also accept a list of chat messages or a formatted prompt\n * const result = await llm.invoke(input);\n * console.log(result);\n * ```\n *\n * ```txt\n * AIMessage {\n *   \"content\": \"There are a few ways to translate \\\"I love programming\\\" into French, depending on the level of formality and nuance you want to convey:\\n\\n**Formal:**\\n\\n* **J'aime la programmation.** (This is the most literal and formal translation.)\\n\\n**Informal:**\\n\\n* **J'adore programmer.** (This is a more enthusiastic and informal translation.)\\n* **J'aime beaucoup programmer.** (This is a slightly less enthusiastic but still informal translation.)\\n\\n**More specific:**\\n\\n* **J'aime beaucoup coder.** (This specifically refers to writing code.)\\n* **J'aime beaucoup dvelopper des logiciels.** (This specifically refers to developing software.)\\n\\nThe best translation will depend on the context and your intended audience. \\n\",\n *   \"response_metadata\": {\n *     \"finishReason\": \"STOP\",\n *     \"index\": 0,\n *     \"safetyRatings\": [\n *       {\n *         \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n *         \"probability\": \"NEGLIGIBLE\"\n *       },\n *       {\n *         \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n *         \"probability\": \"NEGLIGIBLE\"\n *       },\n *       {\n *         \"category\": \"HARM_CATEGORY_HARASSMENT\",\n *         \"probability\": \"NEGLIGIBLE\"\n *       },\n *       {\n *         \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n *         \"probability\": \"NEGLIGIBLE\"\n *       }\n *     ]\n *   },\n *   \"usage_metadata\": {\n *     \"input_tokens\": 10,\n *     \"output_tokens\": 149,\n *     \"total_tokens\": 159\n *   }\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Streaming Chunks</strong></summary>\n *\n * ```typescript\n * for await (const chunk of await llm.stream(input)) {\n *   console.log(chunk);\n * }\n * ```\n *\n * ```txt\n * AIMessageChunk {\n *   \"content\": \"There\",\n *   \"response_metadata\": {\n *     \"index\": 0\n *   }\n *   \"usage_metadata\": {\n *     \"input_tokens\": 10,\n *     \"output_tokens\": 1,\n *     \"total_tokens\": 11\n *   }\n * }\n * AIMessageChunk {\n *   \"content\": \" are a few ways to translate \\\"I love programming\\\" into French, depending on\",\n * }\n * AIMessageChunk {\n *   \"content\": \" the level of formality and nuance you want to convey:\\n\\n**Formal:**\\n\\n\",\n * }\n * AIMessageChunk {\n *   \"content\": \"* **J'aime la programmation.** (This is the most literal and formal translation.)\\n\\n**Informal:**\\n\\n* **J'adore programmer.** (This\",\n * }\n * AIMessageChunk {\n *   \"content\": \" is a more enthusiastic and informal translation.)\\n* **J'aime beaucoup programmer.** (This is a slightly less enthusiastic but still informal translation.)\\n\\n**More\",\n * }\n * AIMessageChunk {\n *   \"content\": \" specific:**\\n\\n* **J'aime beaucoup coder.** (This specifically refers to writing code.)\\n* **J'aime beaucoup dvelopper des logiciels.** (This specifically refers to developing software.)\\n\\nThe best translation will depend on the context and\",\n * }\n * AIMessageChunk {\n *   \"content\": \" your intended audience. \\n\",\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Aggregate Streamed Chunks</strong></summary>\n *\n * ```typescript\n * import { AIMessageChunk } from '@langchain/core/messages';\n * import { concat } from '@langchain/core/utils/stream';\n *\n * const stream = await llm.stream(input);\n * let full: AIMessageChunk | undefined;\n * for await (const chunk of stream) {\n *   full = !full ? chunk : concat(full, chunk);\n * }\n * console.log(full);\n * ```\n *\n * ```txt\n * AIMessageChunk {\n *   \"content\": \"There are a few ways to translate \\\"I love programming\\\" into French, depending on the level of formality and nuance you want to convey:\\n\\n**Formal:**\\n\\n* **J'aime la programmation.** (This is the most literal and formal translation.)\\n\\n**Informal:**\\n\\n* **J'adore programmer.** (This is a more enthusiastic and informal translation.)\\n* **J'aime beaucoup programmer.** (This is a slightly less enthusiastic but still informal translation.)\\n\\n**More specific:**\\n\\n* **J'aime beaucoup coder.** (This specifically refers to writing code.)\\n* **J'aime beaucoup dvelopper des logiciels.** (This specifically refers to developing software.)\\n\\nThe best translation will depend on the context and your intended audience. \\n\",\n *   \"usage_metadata\": {\n *     \"input_tokens\": 10,\n *     \"output_tokens\": 277,\n *     \"total_tokens\": 287\n *   }\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Bind tools</strong></summary>\n *\n * ```typescript\n * import { z } from 'zod';\n *\n * const GetWeather = {\n *   name: \"GetWeather\",\n *   description: \"Get the current weather in a given location\",\n *   schema: z.object({\n *     location: z.string().describe(\"The city and state, e.g. San Francisco, CA\")\n *   }),\n * }\n *\n * const GetPopulation = {\n *   name: \"GetPopulation\",\n *   description: \"Get the current population in a given location\",\n *   schema: z.object({\n *     location: z.string().describe(\"The city and state, e.g. San Francisco, CA\")\n *   }),\n * }\n *\n * const llmWithTools = llm.bindTools([GetWeather, GetPopulation]);\n * const aiMsg = await llmWithTools.invoke(\n *   \"Which city is hotter today and which is bigger: LA or NY?\"\n * );\n * console.log(aiMsg.tool_calls);\n * ```\n *\n * ```txt\n * [\n *   {\n *     name: 'GetWeather',\n *     args: { location: 'Los Angeles, CA' },\n *     type: 'tool_call'\n *   },\n *   {\n *     name: 'GetWeather',\n *     args: { location: 'New York, NY' },\n *     type: 'tool_call'\n *   },\n *   {\n *     name: 'GetPopulation',\n *     args: { location: 'Los Angeles, CA' },\n *     type: 'tool_call'\n *   },\n *   {\n *     name: 'GetPopulation',\n *     args: { location: 'New York, NY' },\n *     type: 'tool_call'\n *   }\n * ]\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Structured Output</strong></summary>\n *\n * ```typescript\n * const Joke = z.object({\n *   setup: z.string().describe(\"The setup of the joke\"),\n *   punchline: z.string().describe(\"The punchline to the joke\"),\n *   rating: z.number().optional().describe(\"How funny the joke is, from 1 to 10\")\n * }).describe('Joke to tell user.');\n *\n * const structuredLlm = llm.withStructuredOutput(Joke, { name: \"Joke\" });\n * const jokeResult = await structuredLlm.invoke(\"Tell me a joke about cats\");\n * console.log(jokeResult);\n * ```\n *\n * ```txt\n * {\n *   setup: \"Why don\\\\'t cats play poker?\",\n *   punchline: \"Why don\\\\'t cats play poker? Because they always have an ace up their sleeve!\"\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Multimodal</strong></summary>\n *\n * ```typescript\n * import { HumanMessage } from '@langchain/core/messages';\n *\n * const imageUrl = \"https://example.com/image.jpg\";\n * const imageData = await fetch(imageUrl).then(res => res.arrayBuffer());\n * const base64Image = Buffer.from(imageData).toString('base64');\n *\n * const message = new HumanMessage({\n *   content: [\n *     { type: \"text\", text: \"describe the weather in this image\" },\n *     {\n *       type: \"image_url\",\n *       image_url: { url: `data:image/jpeg;base64,${base64Image}` },\n *     },\n *   ]\n * });\n *\n * const imageDescriptionAiMsg = await llm.invoke([message]);\n * console.log(imageDescriptionAiMsg.content);\n * ```\n *\n * ```txt\n * The weather in the image appears to be clear and sunny. The sky is mostly blue with a few scattered white clouds, indicating fair weather. The bright sunlight is casting shadows on the green, grassy hill, suggesting it is a pleasant day with good visibility. There are no signs of rain or stormy conditions.\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Usage Metadata</strong></summary>\n *\n * ```typescript\n * const aiMsgForMetadata = await llm.invoke(input);\n * console.log(aiMsgForMetadata.usage_metadata);\n * ```\n *\n * ```txt\n * { input_tokens: 10, output_tokens: 149, total_tokens: 159 }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Response Metadata</strong></summary>\n *\n * ```typescript\n * const aiMsgForResponseMetadata = await llm.invoke(input);\n * console.log(aiMsgForResponseMetadata.response_metadata);\n * ```\n *\n * ```txt\n * {\n *   finishReason: 'STOP',\n *   index: 0,\n *   safetyRatings: [\n *     {\n *       category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n *       probability: 'NEGLIGIBLE'\n *     },\n *     {\n *       category: 'HARM_CATEGORY_HATE_SPEECH',\n *       probability: 'NEGLIGIBLE'\n *     },\n *     { category: 'HARM_CATEGORY_HARASSMENT', probability: 'NEGLIGIBLE' },\n *     {\n *       category: 'HARM_CATEGORY_DANGEROUS_CONTENT',\n *       probability: 'NEGLIGIBLE'\n *     }\n *   ]\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Document Messages</strong></summary>\n *\n * This example will show you how to pass documents such as PDFs to Google\n * Generative AI through messages.\n *\n * ```typescript\n * const pdfPath = \"/Users/my_user/Downloads/invoice.pdf\";\n * const pdfBase64 = await fs.readFile(pdfPath, \"base64\");\n *\n * const response = await llm.invoke([\n *   [\"system\", \"Use the provided documents to answer the question\"],\n *   [\n *     \"user\",\n *     [\n *       {\n *         type: \"application/pdf\", // If the `type` field includes a single slash (`/`), it will be treated as inline data.\n *         data: pdfBase64,\n *       },\n *       {\n *         type: \"text\",\n *         text: \"Summarize the contents of this PDF\",\n *       },\n *     ],\n *   ],\n * ]);\n *\n * console.log(response.content);\n * ```\n *\n * ```txt\n * This is a billing invoice from Twitter Developers for X API Basic Access. The transaction date is January 7, 2025,\n * and the amount is $194.34, which has been paid. The subscription period is from January 7, 2025 21:02 to February 7, 2025 00:00 (UTC).\n * The tax is $0.00, with a tax rate of 0%. The total amount is $194.34. The payment was made using a Visa card ending in 7022,\n * expiring in 12/2026. The billing address is Brace Sproul, 1234 Main Street, San Francisco, CA, US 94103. The company being billed is\n * X Corp, located at 865 FM 1209 Building 2, Bastrop, TX, US 78602. Terms and conditions apply.\n * ```\n * </details>\n *\n * <br />\n */\nexport class ChatGoogleGenerativeAI extends BaseChatModel {\n    static lc_name() {\n        return \"ChatGoogleGenerativeAI\";\n    }\n    get lc_secrets() {\n        return {\n            apiKey: \"GOOGLE_API_KEY\",\n        };\n    }\n    get lc_aliases() {\n        return {\n            apiKey: \"google_api_key\",\n        };\n    }\n    get _isMultimodalModel() {\n        return (this.model.includes(\"vision\") ||\n            this.model.startsWith(\"gemini-1.5\") ||\n            this.model.startsWith(\"gemini-2\"));\n    }\n    constructor(fields) {\n        super(fields ?? {});\n        Object.defineProperty(this, \"lc_serializable\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"lc_namespace\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: [\"langchain\", \"chat_models\", \"google_genai\"]\n        });\n        Object.defineProperty(this, \"modelName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"gemini-pro\"\n        });\n        Object.defineProperty(this, \"model\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"gemini-pro\"\n        });\n        Object.defineProperty(this, \"temperature\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        }); // default value chosen based on model\n        Object.defineProperty(this, \"maxOutputTokens\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"topP\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        }); // default value chosen based on model\n        Object.defineProperty(this, \"topK\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        }); // default value chosen based on model\n        Object.defineProperty(this, \"stopSequences\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: []\n        });\n        Object.defineProperty(this, \"safetySettings\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"apiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"streaming\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"streamUsage\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"convertSystemMessageToHumanContent\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"client\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.modelName =\n            fields?.model?.replace(/^models\\//, \"\") ??\n                fields?.modelName?.replace(/^models\\//, \"\") ??\n                this.model;\n        this.model = this.modelName;\n        this.maxOutputTokens = fields?.maxOutputTokens ?? this.maxOutputTokens;\n        if (this.maxOutputTokens && this.maxOutputTokens < 0) {\n            throw new Error(\"`maxOutputTokens` must be a positive integer\");\n        }\n        this.temperature = fields?.temperature ?? this.temperature;\n        if (this.temperature && (this.temperature < 0 || this.temperature > 2)) {\n            throw new Error(\"`temperature` must be in the range of [0.0,2.0]\");\n        }\n        this.topP = fields?.topP ?? this.topP;\n        if (this.topP && this.topP < 0) {\n            throw new Error(\"`topP` must be a positive integer\");\n        }\n        if (this.topP && this.topP > 1) {\n            throw new Error(\"`topP` must be below 1.\");\n        }\n        this.topK = fields?.topK ?? this.topK;\n        if (this.topK && this.topK < 0) {\n            throw new Error(\"`topK` must be a positive integer\");\n        }\n        this.stopSequences = fields?.stopSequences ?? this.stopSequences;\n        this.apiKey = fields?.apiKey ?? getEnvironmentVariable(\"GOOGLE_API_KEY\");\n        if (!this.apiKey) {\n            throw new Error(\"Please set an API key for Google GenerativeAI \" +\n                \"in the environment variable GOOGLE_API_KEY \" +\n                \"or in the `apiKey` field of the \" +\n                \"ChatGoogleGenerativeAI constructor\");\n        }\n        this.safetySettings = fields?.safetySettings ?? this.safetySettings;\n        if (this.safetySettings && this.safetySettings.length > 0) {\n            const safetySettingsSet = new Set(this.safetySettings.map((s) => s.category));\n            if (safetySettingsSet.size !== this.safetySettings.length) {\n                throw new Error(\"The categories in `safetySettings` array must be unique\");\n            }\n        }\n        this.streaming = fields?.streaming ?? this.streaming;\n        this.client = new GenerativeAI(this.apiKey).getGenerativeModel({\n            model: this.model,\n            safetySettings: this.safetySettings,\n            generationConfig: {\n                candidateCount: 1,\n                stopSequences: this.stopSequences,\n                maxOutputTokens: this.maxOutputTokens,\n                temperature: this.temperature,\n                topP: this.topP,\n                topK: this.topK,\n                ...(fields?.json ? { responseMimeType: \"application/json\" } : {}),\n            },\n        }, {\n            apiVersion: fields?.apiVersion,\n            baseUrl: fields?.baseUrl,\n        });\n        this.streamUsage = fields?.streamUsage ?? this.streamUsage;\n    }\n    useCachedContent(cachedContent, modelParams, requestOptions) {\n        if (!this.apiKey)\n            return;\n        this.client = new GenerativeAI(this.apiKey).getGenerativeModelFromCachedContent(cachedContent, modelParams, requestOptions);\n    }\n    get useSystemInstruction() {\n        return typeof this.convertSystemMessageToHumanContent === \"boolean\"\n            ? !this.convertSystemMessageToHumanContent\n            : this.computeUseSystemInstruction;\n    }\n    get computeUseSystemInstruction() {\n        // This works on models from April 2024 and later\n        //   Vertex AI: gemini-1.5-pro and gemini-1.0-002 and later\n        //   AI Studio: gemini-1.5-pro-latest\n        if (this.modelName === \"gemini-1.0-pro-001\") {\n            return false;\n        }\n        else if (this.modelName.startsWith(\"gemini-pro-vision\")) {\n            return false;\n        }\n        else if (this.modelName.startsWith(\"gemini-1.0-pro-vision\")) {\n            return false;\n        }\n        else if (this.modelName === \"gemini-pro\") {\n            // on AI Studio gemini-pro is still pointing at gemini-1.0-pro-001\n            return false;\n        }\n        return true;\n    }\n    getLsParams(options) {\n        return {\n            ls_provider: \"google_genai\",\n            ls_model_name: this.model,\n            ls_model_type: \"chat\",\n            ls_temperature: this.client.generationConfig.temperature,\n            ls_max_tokens: this.client.generationConfig.maxOutputTokens,\n            ls_stop: options.stop,\n        };\n    }\n    _combineLLMOutput() {\n        return [];\n    }\n    _llmType() {\n        return \"googlegenerativeai\";\n    }\n    bindTools(tools, kwargs) {\n        return this.bind({ tools: convertToolsToGenAI(tools)?.tools, ...kwargs });\n    }\n    invocationParams(options) {\n        const toolsAndConfig = options?.tools?.length\n            ? convertToolsToGenAI(options.tools, {\n                toolChoice: options.tool_choice,\n                allowedFunctionNames: options.allowedFunctionNames,\n            })\n            : undefined;\n        return {\n            ...(toolsAndConfig?.tools ? { tools: toolsAndConfig.tools } : {}),\n            ...(toolsAndConfig?.toolConfig\n                ? { toolConfig: toolsAndConfig.toolConfig }\n                : {}),\n        };\n    }\n    async _generate(messages, options, runManager) {\n        const prompt = convertBaseMessagesToContent(messages, this._isMultimodalModel, this.useSystemInstruction);\n        let actualPrompt = prompt;\n        if (prompt[0].role === \"system\") {\n            const [systemInstruction] = prompt;\n            this.client.systemInstruction = systemInstruction;\n            actualPrompt = prompt.slice(1);\n        }\n        const parameters = this.invocationParams(options);\n        // Handle streaming\n        if (this.streaming) {\n            const tokenUsage = {};\n            const stream = this._streamResponseChunks(messages, options, runManager);\n            const finalChunks = {};\n            for await (const chunk of stream) {\n                const index = chunk.generationInfo?.completion ?? 0;\n                if (finalChunks[index] === undefined) {\n                    finalChunks[index] = chunk;\n                }\n                else {\n                    finalChunks[index] = finalChunks[index].concat(chunk);\n                }\n            }\n            const generations = Object.entries(finalChunks)\n                .sort(([aKey], [bKey]) => parseInt(aKey, 10) - parseInt(bKey, 10))\n                .map(([_, value]) => value);\n            return { generations, llmOutput: { estimatedTokenUsage: tokenUsage } };\n        }\n        const res = await this.completionWithRetry({\n            ...parameters,\n            contents: actualPrompt,\n        });\n        let usageMetadata;\n        if (\"usageMetadata\" in res.response) {\n            const genAIUsageMetadata = res.response.usageMetadata;\n            usageMetadata = {\n                input_tokens: genAIUsageMetadata.promptTokenCount ?? 0,\n                output_tokens: genAIUsageMetadata.candidatesTokenCount ?? 0,\n                total_tokens: genAIUsageMetadata.totalTokenCount ?? 0,\n            };\n        }\n        const generationResult = mapGenerateContentResultToChatResult(res.response, {\n            usageMetadata,\n        });\n        await runManager?.handleLLMNewToken(generationResult.generations[0].text ?? \"\");\n        return generationResult;\n    }\n    async *_streamResponseChunks(messages, options, runManager) {\n        const prompt = convertBaseMessagesToContent(messages, this._isMultimodalModel, this.useSystemInstruction);\n        let actualPrompt = prompt;\n        if (prompt[0].role === \"system\") {\n            const [systemInstruction] = prompt;\n            this.client.systemInstruction = systemInstruction;\n            actualPrompt = prompt.slice(1);\n        }\n        const parameters = this.invocationParams(options);\n        const request = {\n            ...parameters,\n            contents: actualPrompt,\n        };\n        const stream = await this.caller.callWithOptions({ signal: options?.signal }, async () => {\n            const { stream } = await this.client.generateContentStream(request);\n            return stream;\n        });\n        let usageMetadata;\n        let index = 0;\n        for await (const response of stream) {\n            if (\"usageMetadata\" in response &&\n                this.streamUsage !== false &&\n                options.streamUsage !== false) {\n                const genAIUsageMetadata = response.usageMetadata;\n                if (!usageMetadata) {\n                    usageMetadata = {\n                        input_tokens: genAIUsageMetadata.promptTokenCount ?? 0,\n                        output_tokens: genAIUsageMetadata.candidatesTokenCount ?? 0,\n                        total_tokens: genAIUsageMetadata.totalTokenCount ?? 0,\n                    };\n                }\n                else {\n                    // Under the hood, LangChain combines the prompt tokens. Google returns the updated\n                    // total each time, so we need to find the difference between the tokens.\n                    const outputTokenDiff = (genAIUsageMetadata.candidatesTokenCount ?? 0) -\n                        usageMetadata.output_tokens;\n                    usageMetadata = {\n                        input_tokens: 0,\n                        output_tokens: outputTokenDiff,\n                        total_tokens: outputTokenDiff,\n                    };\n                }\n            }\n            const chunk = convertResponseContentToChatGenerationChunk(response, {\n                usageMetadata,\n                index,\n            });\n            index += 1;\n            if (!chunk) {\n                continue;\n            }\n            yield chunk;\n            await runManager?.handleLLMNewToken(chunk.text ?? \"\");\n        }\n    }\n    async completionWithRetry(request, options) {\n        return this.caller.callWithOptions({ signal: options?.signal }, async () => {\n            try {\n                return await this.client.generateContent(request);\n                // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            }\n            catch (e) {\n                // TODO: Improve error handling\n                if (e.message?.includes(\"400 Bad Request\")) {\n                    e.status = 400;\n                }\n                throw e;\n            }\n        });\n    }\n    withStructuredOutput(outputSchema, config) {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        const schema = outputSchema;\n        const name = config?.name;\n        const method = config?.method;\n        const includeRaw = config?.includeRaw;\n        if (method === \"jsonMode\") {\n            throw new Error(`ChatGoogleGenerativeAI only supports \"functionCalling\" as a method.`);\n        }\n        let functionName = name ?? \"extract\";\n        let outputParser;\n        let tools;\n        if (isZodSchema(schema)) {\n            const jsonSchema = zodToGenerativeAIParameters(schema);\n            tools = [\n                {\n                    functionDeclarations: [\n                        {\n                            name: functionName,\n                            description: jsonSchema.description ?? \"A function available to call.\",\n                            parameters: jsonSchema,\n                        },\n                    ],\n                },\n            ];\n            outputParser = new GoogleGenerativeAIToolsOutputParser({\n                returnSingle: true,\n                keyName: functionName,\n                zodSchema: schema,\n            });\n        }\n        else {\n            let geminiFunctionDefinition;\n            if (typeof schema.name === \"string\" &&\n                typeof schema.parameters === \"object\" &&\n                schema.parameters != null) {\n                geminiFunctionDefinition = schema;\n                functionName = schema.name;\n            }\n            else {\n                geminiFunctionDefinition = {\n                    name: functionName,\n                    description: schema.description ?? \"\",\n                    parameters: schema,\n                };\n            }\n            tools = [\n                {\n                    functionDeclarations: [geminiFunctionDefinition],\n                },\n            ];\n            outputParser = new GoogleGenerativeAIToolsOutputParser({\n                returnSingle: true,\n                keyName: functionName,\n            });\n        }\n        const llm = this.bind({\n            tools,\n            tool_choice: functionName,\n        });\n        if (!includeRaw) {\n            return llm.pipe(outputParser).withConfig({\n                runName: \"ChatGoogleGenerativeAIStructuredOutput\",\n            });\n        }\n        const parserAssign = RunnablePassthrough.assign({\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            parsed: (input, config) => outputParser.invoke(input.raw, config),\n        });\n        const parserNone = RunnablePassthrough.assign({\n            parsed: () => null,\n        });\n        const parsedWithFallback = parserAssign.withFallbacks({\n            fallbacks: [parserNone],\n        });\n        return RunnableSequence.from([\n            {\n                raw: llm,\n            },\n            parsedWithFallback,\n        ]).withConfig({\n            runName: \"StructuredOutputRunnable\",\n        });\n    }\n}\n", "import { GoogleGenerativeAI } from \"@google/generative-ai\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport { Embeddings } from \"@langchain/core/embeddings\";\nimport { chunkArray } from \"@langchain/core/utils/chunk_array\";\n/**\n * Class that extends the Embeddings class and provides methods for\n * generating embeddings using the Google Palm API.\n * @example\n * ```typescript\n * const model = new GoogleGenerativeAIEmbeddings({\n *   apiKey: \"<YOUR API KEY>\",\n *   modelName: \"embedding-001\",\n * });\n *\n * // Embed a single query\n * const res = await model.embedQuery(\n *   \"What would be a good company name for a company that makes colorful socks?\"\n * );\n * console.log({ res });\n *\n * // Embed multiple documents\n * const documentRes = await model.embedDocuments([\"Hello world\", \"Bye bye\"]);\n * console.log({ documentRes });\n * ```\n */\nexport class GoogleGenerativeAIEmbeddings extends Embeddings {\n    constructor(fields) {\n        super(fields ?? {});\n        Object.defineProperty(this, \"apiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"modelName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"embedding-001\"\n        });\n        Object.defineProperty(this, \"model\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"embedding-001\"\n        });\n        Object.defineProperty(this, \"taskType\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"title\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"stripNewLines\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"maxBatchSize\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 100\n        }); // Max batch size for embedDocuments set by GenerativeModel client's batchEmbedContents call\n        Object.defineProperty(this, \"client\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.modelName =\n            fields?.model?.replace(/^models\\//, \"\") ??\n                fields?.modelName?.replace(/^models\\//, \"\") ??\n                this.modelName;\n        this.model = this.modelName;\n        this.taskType = fields?.taskType ?? this.taskType;\n        this.title = fields?.title ?? this.title;\n        if (this.title && this.taskType !== \"RETRIEVAL_DOCUMENT\") {\n            throw new Error(\"title can only be sepcified with TaskType.RETRIEVAL_DOCUMENT\");\n        }\n        this.apiKey = fields?.apiKey ?? getEnvironmentVariable(\"GOOGLE_API_KEY\");\n        if (!this.apiKey) {\n            throw new Error(\"Please set an API key for Google GenerativeAI \" +\n                \"in the environmentb variable GOOGLE_API_KEY \" +\n                \"or in the `apiKey` field of the \" +\n                \"GoogleGenerativeAIEmbeddings constructor\");\n        }\n        this.client = new GoogleGenerativeAI(this.apiKey).getGenerativeModel({\n            model: this.model,\n        });\n    }\n    _convertToContent(text) {\n        const cleanedText = this.stripNewLines ? text.replace(/\\n/g, \" \") : text;\n        return {\n            content: { role: \"user\", parts: [{ text: cleanedText }] },\n            taskType: this.taskType,\n            title: this.title,\n        };\n    }\n    async _embedQueryContent(text) {\n        const req = this._convertToContent(text);\n        const res = await this.client.embedContent(req);\n        return res.embedding.values ?? [];\n    }\n    async _embedDocumentsContent(documents) {\n        const batchEmbedChunks = chunkArray(documents, this.maxBatchSize);\n        const batchEmbedRequests = batchEmbedChunks.map((chunk) => ({\n            requests: chunk.map((doc) => this._convertToContent(doc)),\n        }));\n        const responses = await Promise.allSettled(batchEmbedRequests.map((req) => this.client.batchEmbedContents(req)));\n        const embeddings = responses.flatMap((res, idx) => {\n            if (res.status === \"fulfilled\") {\n                return res.value.embeddings.map((e) => e.values || []);\n            }\n            else {\n                return Array(batchEmbedChunks[idx].length).fill([]);\n            }\n        });\n        return embeddings;\n    }\n    /**\n     * Method that takes a document as input and returns a promise that\n     * resolves to an embedding for the document. It calls the _embedText\n     * method with the document as the input.\n     * @param document Document for which to generate an embedding.\n     * @returns Promise that resolves to an embedding for the input document.\n     */\n    embedQuery(document) {\n        return this.caller.call(this._embedQueryContent.bind(this), document);\n    }\n    /**\n     * Method that takes an array of documents as input and returns a promise\n     * that resolves to a 2D array of embeddings for each document. It calls\n     * the _embedText method for each document in the array.\n     * @param documents Array of documents for which to generate embeddings.\n     * @returns Promise that resolves to a 2D array of embeddings for each input document.\n     */\n    embedDocuments(documents) {\n        return this.caller.call(this._embedDocumentsContent.bind(this), documents);\n    }\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAKA,IAAI;AAAA,CACH,SAAUA,aAAY;AAEnB,EAAAA,YAAW,QAAQ,IAAI;AAEvB,EAAAA,YAAW,QAAQ,IAAI;AAEvB,EAAAA,YAAW,SAAS,IAAI;AAExB,EAAAA,YAAW,SAAS,IAAI;AAExB,EAAAA,YAAW,OAAO,IAAI;AAEtB,EAAAA,YAAW,QAAQ,IAAI;AAC3B,GAAG,eAAe,aAAa,CAAC,EAAE;AAqBlC,IAAI;AAAA,CACH,SAAUC,yBAAwB;AAC/B,EAAAA,wBAAuB,sBAAsB,IAAI;AACjD,EAAAA,wBAAuB,QAAQ,IAAI;AACvC,GAAG,2BAA2B,yBAAyB,CAAC,EAAE;AAK1D,IAAI;AAAA,CACH,SAAUC,UAAS;AAIhB,EAAAA,SAAQ,qBAAqB,IAAI;AAIjC,EAAAA,SAAQ,YAAY,IAAI;AAKxB,EAAAA,SAAQ,gBAAgB,IAAI;AAK5B,EAAAA,SAAQ,2BAA2B,IAAI;AAC3C,GAAG,YAAY,UAAU,CAAC,EAAE;AAsB5B,IAAM,iBAAiB,CAAC,QAAQ,SAAS,YAAY,QAAQ;AAK7D,IAAI;AAAA,CACH,SAAUC,eAAc;AACrB,EAAAA,cAAa,2BAA2B,IAAI;AAC5C,EAAAA,cAAa,2BAA2B,IAAI;AAC5C,EAAAA,cAAa,iCAAiC,IAAI;AAClD,EAAAA,cAAa,0BAA0B,IAAI;AAC3C,EAAAA,cAAa,iCAAiC,IAAI;AACtD,GAAG,iBAAiB,eAAe,CAAC,EAAE;AAKtC,IAAI;AAAA,CACH,SAAUC,qBAAoB;AAE3B,EAAAA,oBAAmB,kCAAkC,IAAI;AAEzD,EAAAA,oBAAmB,qBAAqB,IAAI;AAE5C,EAAAA,oBAAmB,wBAAwB,IAAI;AAE/C,EAAAA,oBAAmB,iBAAiB,IAAI;AAExC,EAAAA,oBAAmB,YAAY,IAAI;AACvC,GAAG,uBAAuB,qBAAqB,CAAC,EAAE;AAKlD,IAAI;AAAA,CACH,SAAUC,kBAAiB;AAExB,EAAAA,iBAAgB,8BAA8B,IAAI;AAElD,EAAAA,iBAAgB,YAAY,IAAI;AAEhC,EAAAA,iBAAgB,KAAK,IAAI;AAEzB,EAAAA,iBAAgB,QAAQ,IAAI;AAE5B,EAAAA,iBAAgB,MAAM,IAAI;AAC9B,GAAG,oBAAoB,kBAAkB,CAAC,EAAE;AAK5C,IAAI;AAAA,CACH,SAAUC,cAAa;AAEpB,EAAAA,aAAY,4BAA4B,IAAI;AAE5C,EAAAA,aAAY,QAAQ,IAAI;AAExB,EAAAA,aAAY,OAAO,IAAI;AAC3B,GAAG,gBAAgB,cAAc,CAAC,EAAE;AAKpC,IAAI;AAAA,CACH,SAAUC,eAAc;AAErB,EAAAA,cAAa,2BAA2B,IAAI;AAE5C,EAAAA,cAAa,MAAM,IAAI;AAEvB,EAAAA,cAAa,YAAY,IAAI;AAE7B,EAAAA,cAAa,QAAQ,IAAI;AAEzB,EAAAA,cAAa,YAAY,IAAI;AAE7B,EAAAA,cAAa,UAAU,IAAI;AAE3B,EAAAA,cAAa,OAAO,IAAI;AAC5B,GAAG,iBAAiB,eAAe,CAAC,EAAE;AAKtC,IAAI;AAAA,CACH,SAAUC,WAAU;AACjB,EAAAA,UAAS,uBAAuB,IAAI;AACpC,EAAAA,UAAS,iBAAiB,IAAI;AAC9B,EAAAA,UAAS,oBAAoB,IAAI;AACjC,EAAAA,UAAS,qBAAqB,IAAI;AAClC,EAAAA,UAAS,gBAAgB,IAAI;AAC7B,EAAAA,UAAS,YAAY,IAAI;AAC7B,GAAG,aAAa,WAAW,CAAC,EAAE;AAI9B,IAAI;AAAA,CACH,SAAUC,sBAAqB;AAE5B,EAAAA,qBAAoB,kBAAkB,IAAI;AAG1C,EAAAA,qBAAoB,MAAM,IAAI;AAK9B,EAAAA,qBAAoB,KAAK,IAAI;AAG7B,EAAAA,qBAAoB,MAAM,IAAI;AAClC,GAAG,wBAAwB,sBAAsB,CAAC,EAAE;AAKpD,IAAI;AAAA,CACH,SAAUC,uBAAsB;AAE7B,EAAAA,sBAAqB,kBAAkB,IAAI;AAE3C,EAAAA,sBAAqB,cAAc,IAAI;AAC3C,GAAG,yBAAyB,uBAAuB,CAAC,EAAE;AAsBtD,IAAM,0BAAN,cAAsC,MAAM;AAAA,EACxC,YAAY,SAAS;AACjB,UAAM,+BAA+B,OAAO,EAAE;AAAA,EAClD;AACJ;AAMA,IAAM,kCAAN,cAA8C,wBAAwB;AAAA,EAClE,YAAY,SAAS,UAAU;AAC3B,UAAM,OAAO;AACb,SAAK,WAAW;AAAA,EACpB;AACJ;AAMA,IAAM,+BAAN,cAA2C,wBAAwB;AAAA,EAC/D,YAAY,SAAS,QAAQ,YAAY,cAAc;AACnD,UAAM,OAAO;AACb,SAAK,SAAS;AACd,SAAK,aAAa;AAClB,SAAK,eAAe;AAAA,EACxB;AACJ;AAKA,IAAM,sCAAN,cAAkD,wBAAwB;AAC1E;AAkBA,IAAM,mBAAmB;AACzB,IAAM,sBAAsB;AAK5B,IAAM,kBAAkB;AACxB,IAAM,qBAAqB;AAC3B,IAAI;AAAA,CACH,SAAUC,OAAM;AACb,EAAAA,MAAK,kBAAkB,IAAI;AAC3B,EAAAA,MAAK,yBAAyB,IAAI;AAClC,EAAAA,MAAK,cAAc,IAAI;AACvB,EAAAA,MAAK,eAAe,IAAI;AACxB,EAAAA,MAAK,sBAAsB,IAAI;AACnC,GAAG,SAAS,OAAO,CAAC,EAAE;AACtB,IAAM,aAAN,MAAiB;AAAA,EACb,YAAY,OAAO,MAAM,QAAQ,QAAQ,gBAAgB;AACrD,SAAK,QAAQ;AACb,SAAK,OAAO;AACZ,SAAK,SAAS;AACd,SAAK,SAAS;AACd,SAAK,iBAAiB;AAAA,EAC1B;AAAA,EACA,WAAW;AACP,QAAI,IAAI;AACR,UAAM,eAAe,KAAK,KAAK,oBAAoB,QAAQ,OAAO,SAAS,SAAS,GAAG,eAAe;AACtG,UAAM,YAAY,KAAK,KAAK,oBAAoB,QAAQ,OAAO,SAAS,SAAS,GAAG,YAAY;AAChG,QAAI,MAAM,GAAG,OAAO,IAAI,UAAU,IAAI,KAAK,KAAK,IAAI,KAAK,IAAI;AAC7D,QAAI,KAAK,QAAQ;AACb,aAAO;AAAA,IACX;AACA,WAAO;AAAA,EACX;AACJ;AAIA,SAAS,iBAAiB,gBAAgB;AACtC,QAAM,gBAAgB,CAAC;AACvB,MAAI,mBAAmB,QAAQ,mBAAmB,SAAS,SAAS,eAAe,WAAW;AAC1F,kBAAc,KAAK,eAAe,SAAS;AAAA,EAC/C;AACA,gBAAc,KAAK,GAAG,kBAAkB,IAAI,eAAe,EAAE;AAC7D,SAAO,cAAc,KAAK,GAAG;AACjC;AACA,eAAe,WAAW,KAAK;AAC3B,MAAI;AACJ,QAAM,UAAU,IAAI,QAAQ;AAC5B,UAAQ,OAAO,gBAAgB,kBAAkB;AACjD,UAAQ,OAAO,qBAAqB,iBAAiB,IAAI,cAAc,CAAC;AACxE,UAAQ,OAAO,kBAAkB,IAAI,MAAM;AAC3C,MAAI,iBAAiB,KAAK,IAAI,oBAAoB,QAAQ,OAAO,SAAS,SAAS,GAAG;AACtF,MAAI,eAAe;AACf,QAAI,EAAE,yBAAyB,UAAU;AACrC,UAAI;AACA,wBAAgB,IAAI,QAAQ,aAAa;AAAA,MAC7C,SACO,GAAG;AACN,cAAM,IAAI,oCAAoC,yCAAyC,KAAK,UAAU,aAAa,CAAC,gBAAgB,EAAE,OAAO,EAAE;AAAA,MACnJ;AAAA,IACJ;AACA,eAAW,CAAC,YAAY,WAAW,KAAK,cAAc,QAAQ,GAAG;AAC7D,UAAI,eAAe,kBAAkB;AACjC,cAAM,IAAI,oCAAoC,mCAAmC,UAAU,EAAE;AAAA,MACjG,WACS,eAAe,qBAAqB;AACzC,cAAM,IAAI,oCAAoC,eAAe,UAAU,4CAA4C;AAAA,MACvH;AACA,cAAQ,OAAO,YAAY,WAAW;AAAA,IAC1C;AAAA,EACJ;AACA,SAAO;AACX;AACA,eAAe,sBAAsB,OAAO,MAAM,QAAQ,QAAQ,MAAM,gBAAgB;AACpF,QAAM,MAAM,IAAI,WAAW,OAAO,MAAM,QAAQ,QAAQ,cAAc;AACtE,SAAO;AAAA,IACH,KAAK,IAAI,SAAS;AAAA,IAClB,cAAc,OAAO,OAAO,OAAO,OAAO,CAAC,GAAG,kBAAkB,cAAc,CAAC,GAAG,EAAE,QAAQ,QAAQ,SAAS,MAAM,WAAW,GAAG,GAAG,KAAK,CAAC;AAAA,EAC9I;AACJ;AACA,eAAe,iBAAiB,OAAO,MAAM,QAAQ,QAAQ,MAAM,iBAAiB,CAAC,GAErF,UAAU,OAAO;AACb,QAAM,EAAE,KAAK,aAAa,IAAI,MAAM,sBAAsB,OAAO,MAAM,QAAQ,QAAQ,MAAM,cAAc;AAC3G,SAAO,YAAY,KAAK,cAAc,OAAO;AACjD;AACA,eAAe,YAAY,KAAK,cAAc,UAAU,OAAO;AAC3D,MAAI;AACJ,MAAI;AACA,eAAW,MAAM,QAAQ,KAAK,YAAY;AAAA,EAC9C,SACO,GAAG;AACN,wBAAoB,GAAG,GAAG;AAAA,EAC9B;AACA,MAAI,CAAC,SAAS,IAAI;AACd,UAAM,oBAAoB,UAAU,GAAG;AAAA,EAC3C;AACA,SAAO;AACX;AACA,SAAS,oBAAoB,GAAG,KAAK;AACjC,MAAI,MAAM;AACV,MAAI,EAAE,aAAa,gCACf,aAAa,sCAAsC;AACnD,UAAM,IAAI,wBAAwB,uBAAuB,IAAI,SAAS,CAAC,KAAK,EAAE,OAAO,EAAE;AACvF,QAAI,QAAQ,EAAE;AAAA,EAClB;AACA,QAAM;AACV;AACA,eAAe,oBAAoB,UAAU,KAAK;AAC9C,MAAI,UAAU;AACd,MAAI;AACJ,MAAI;AACA,UAAM,OAAO,MAAM,SAAS,KAAK;AACjC,cAAU,KAAK,MAAM;AACrB,QAAI,KAAK,MAAM,SAAS;AACpB,iBAAW,IAAI,KAAK,UAAU,KAAK,MAAM,OAAO,CAAC;AACjD,qBAAe,KAAK,MAAM;AAAA,IAC9B;AAAA,EACJ,SACO,GAAG;AAAA,EAEV;AACA,QAAM,IAAI,6BAA6B,uBAAuB,IAAI,SAAS,CAAC,MAAM,SAAS,MAAM,IAAI,SAAS,UAAU,KAAK,OAAO,IAAI,SAAS,QAAQ,SAAS,YAAY,YAAY;AAC9L;AAMA,SAAS,kBAAkB,gBAAgB;AACvC,QAAM,eAAe,CAAC;AACtB,OAAK,mBAAmB,QAAQ,mBAAmB,SAAS,SAAS,eAAe,YAAY,WAAc,mBAAmB,QAAQ,mBAAmB,SAAS,SAAS,eAAe,YAAY,GAAG;AACxM,UAAM,aAAa,IAAI,gBAAgB;AACvC,SAAK,mBAAmB,QAAQ,mBAAmB,SAAS,SAAS,eAAe,YAAY,GAAG;AAC/F,iBAAW,MAAM,WAAW,MAAM,GAAG,eAAe,OAAO;AAAA,IAC/D;AACA,QAAI,mBAAmB,QAAQ,mBAAmB,SAAS,SAAS,eAAe,QAAQ;AACvF,qBAAe,OAAO,iBAAiB,SAAS,MAAM;AAClD,mBAAW,MAAM;AAAA,MACrB,CAAC;AAAA,IACL;AACA,iBAAa,SAAS,WAAW;AAAA,EACrC;AACA,SAAO;AACX;AAsBA,SAAS,WAAW,UAAU;AAC1B,WAAS,OAAO,MAAM;AAClB,QAAI,SAAS,cAAc,SAAS,WAAW,SAAS,GAAG;AACvD,UAAI,SAAS,WAAW,SAAS,GAAG;AAChC,gBAAQ,KAAK,qBAAqB,SAAS,WAAW,MAAM,6HAEU;AAAA,MAC1E;AACA,UAAI,mBAAmB,SAAS,WAAW,CAAC,CAAC,GAAG;AAC5C,cAAM,IAAI,gCAAgC,GAAG,wBAAwB,QAAQ,CAAC,IAAI,QAAQ;AAAA,MAC9F;AACA,aAAO,QAAQ,QAAQ;AAAA,IAC3B,WACS,SAAS,gBAAgB;AAC9B,YAAM,IAAI,gCAAgC,uBAAuB,wBAAwB,QAAQ,CAAC,IAAI,QAAQ;AAAA,IAClH;AACA,WAAO;AAAA,EACX;AAIA,WAAS,eAAe,MAAM;AAC1B,QAAI,SAAS,cAAc,SAAS,WAAW,SAAS,GAAG;AACvD,UAAI,SAAS,WAAW,SAAS,GAAG;AAChC,gBAAQ,KAAK,qBAAqB,SAAS,WAAW,MAAM,uIAEU;AAAA,MAC1E;AACA,UAAI,mBAAmB,SAAS,WAAW,CAAC,CAAC,GAAG;AAC5C,cAAM,IAAI,gCAAgC,GAAG,wBAAwB,QAAQ,CAAC,IAAI,QAAQ;AAAA,MAC9F;AACA,cAAQ,KAAK,8EAC8B;AAC3C,aAAO,iBAAiB,QAAQ,EAAE,CAAC;AAAA,IACvC,WACS,SAAS,gBAAgB;AAC9B,YAAM,IAAI,gCAAgC,gCAAgC,wBAAwB,QAAQ,CAAC,IAAI,QAAQ;AAAA,IAC3H;AACA,WAAO;AAAA,EACX;AACA,WAAS,gBAAgB,MAAM;AAC3B,QAAI,SAAS,cAAc,SAAS,WAAW,SAAS,GAAG;AACvD,UAAI,SAAS,WAAW,SAAS,GAAG;AAChC,gBAAQ,KAAK,qBAAqB,SAAS,WAAW,MAAM,uIAEU;AAAA,MAC1E;AACA,UAAI,mBAAmB,SAAS,WAAW,CAAC,CAAC,GAAG;AAC5C,cAAM,IAAI,gCAAgC,GAAG,wBAAwB,QAAQ,CAAC,IAAI,QAAQ;AAAA,MAC9F;AACA,aAAO,iBAAiB,QAAQ;AAAA,IACpC,WACS,SAAS,gBAAgB;AAC9B,YAAM,IAAI,gCAAgC,gCAAgC,wBAAwB,QAAQ,CAAC,IAAI,QAAQ;AAAA,IAC3H;AACA,WAAO;AAAA,EACX;AACA,SAAO;AACX;AAIA,SAAS,QAAQ,UAAU;AACvB,MAAI,IAAI,IAAI,IAAI;AAChB,QAAM,cAAc,CAAC;AACrB,OAAK,MAAM,KAAK,SAAS,gBAAgB,QAAQ,OAAO,SAAS,SAAS,GAAG,CAAC,EAAE,aAAa,QAAQ,OAAO,SAAS,SAAS,GAAG,OAAO;AACpI,eAAW,SAAS,MAAM,KAAK,SAAS,gBAAgB,QAAQ,OAAO,SAAS,SAAS,GAAG,CAAC,EAAE,aAAa,QAAQ,OAAO,SAAS,SAAS,GAAG,OAAO;AACnJ,UAAI,KAAK,MAAM;AACX,oBAAY,KAAK,KAAK,IAAI;AAAA,MAC9B;AACA,UAAI,KAAK,gBAAgB;AACrB,oBAAY,KAAK,UACb,KAAK,eAAe,WACpB,OACA,KAAK,eAAe,OACpB,SAAS;AAAA,MACjB;AACA,UAAI,KAAK,qBAAqB;AAC1B,oBAAY,KAAK,YAAY,KAAK,oBAAoB,SAAS,SAAS;AAAA,MAC5E;AAAA,IACJ;AAAA,EACJ;AACA,MAAI,YAAY,SAAS,GAAG;AACxB,WAAO,YAAY,KAAK,EAAE;AAAA,EAC9B,OACK;AACD,WAAO;AAAA,EACX;AACJ;AAIA,SAAS,iBAAiB,UAAU;AAChC,MAAI,IAAI,IAAI,IAAI;AAChB,QAAM,gBAAgB,CAAC;AACvB,OAAK,MAAM,KAAK,SAAS,gBAAgB,QAAQ,OAAO,SAAS,SAAS,GAAG,CAAC,EAAE,aAAa,QAAQ,OAAO,SAAS,SAAS,GAAG,OAAO;AACpI,eAAW,SAAS,MAAM,KAAK,SAAS,gBAAgB,QAAQ,OAAO,SAAS,SAAS,GAAG,CAAC,EAAE,aAAa,QAAQ,OAAO,SAAS,SAAS,GAAG,OAAO;AACnJ,UAAI,KAAK,cAAc;AACnB,sBAAc,KAAK,KAAK,YAAY;AAAA,MACxC;AAAA,IACJ;AAAA,EACJ;AACA,MAAI,cAAc,SAAS,GAAG;AAC1B,WAAO;AAAA,EACX,OACK;AACD,WAAO;AAAA,EACX;AACJ;AACA,IAAM,mBAAmB;AAAA,EACrB,aAAa;AAAA,EACb,aAAa;AAAA,EACb,aAAa;AACjB;AACA,SAAS,mBAAmB,WAAW;AACnC,SAAQ,CAAC,CAAC,UAAU,gBAChB,iBAAiB,SAAS,UAAU,YAAY;AACxD;AACA,SAAS,wBAAwB,UAAU;AACvC,MAAI,IAAI,IAAI;AACZ,MAAI,UAAU;AACd,OAAK,CAAC,SAAS,cAAc,SAAS,WAAW,WAAW,MACxD,SAAS,gBAAgB;AACzB,eAAW;AACX,SAAK,KAAK,SAAS,oBAAoB,QAAQ,OAAO,SAAS,SAAS,GAAG,aAAa;AACpF,iBAAW,WAAW,SAAS,eAAe,WAAW;AAAA,IAC7D;AACA,SAAK,KAAK,SAAS,oBAAoB,QAAQ,OAAO,SAAS,SAAS,GAAG,oBAAoB;AAC3F,iBAAW,KAAK,SAAS,eAAe,kBAAkB;AAAA,IAC9D;AAAA,EACJ,YACU,KAAK,SAAS,gBAAgB,QAAQ,OAAO,SAAS,SAAS,GAAG,CAAC,GAAG;AAC5E,UAAM,iBAAiB,SAAS,WAAW,CAAC;AAC5C,QAAI,mBAAmB,cAAc,GAAG;AACpC,iBAAW,gCAAgC,eAAe,YAAY;AACtE,UAAI,eAAe,eAAe;AAC9B,mBAAW,KAAK,eAAe,aAAa;AAAA,MAChD;AAAA,IACJ;AAAA,EACJ;AACA,SAAO;AACX;AAmBA,SAAS,QAAQ,GAAG;AAChB,SAAO,gBAAgB,WAAW,KAAK,IAAI,GAAG,QAAQ,IAAI,QAAQ,CAAC;AACvE;AAEA,SAAS,iBAAiB,SAAS,YAAY,WAAW;AACtD,MAAI,CAAC,OAAO,cAAe,OAAM,IAAI,UAAU,sCAAsC;AACrF,MAAI,IAAI,UAAU,MAAM,SAAS,cAAc,CAAC,CAAC,GAAG,GAAG,IAAI,CAAC;AAC5D,SAAO,IAAI,CAAC,GAAG,KAAK,MAAM,GAAG,KAAK,OAAO,GAAG,KAAK,QAAQ,GAAG,EAAE,OAAO,aAAa,IAAI,WAAY;AAAE,WAAO;AAAA,EAAM,GAAG;AACpH,WAAS,KAAK,GAAG;AAAE,QAAI,EAAE,CAAC,EAAG,GAAE,CAAC,IAAI,SAAU,GAAG;AAAE,aAAO,IAAI,QAAQ,SAAU,GAAG,GAAG;AAAE,UAAE,KAAK,CAAC,GAAG,GAAG,GAAG,CAAC,CAAC,IAAI,KAAK,OAAO,GAAG,CAAC;AAAA,MAAG,CAAC;AAAA,IAAG;AAAA,EAAG;AACzI,WAAS,OAAO,GAAG,GAAG;AAAE,QAAI;AAAE,WAAK,EAAE,CAAC,EAAE,CAAC,CAAC;AAAA,IAAG,SAAS,GAAG;AAAE,aAAO,EAAE,CAAC,EAAE,CAAC,GAAG,CAAC;AAAA,IAAG;AAAA,EAAE;AACjF,WAAS,KAAK,GAAG;AAAE,MAAE,iBAAiB,UAAU,QAAQ,QAAQ,EAAE,MAAM,CAAC,EAAE,KAAK,SAAS,MAAM,IAAI,OAAO,EAAE,CAAC,EAAE,CAAC,GAAG,CAAC;AAAA,EAAG;AACvH,WAAS,QAAQ,OAAO;AAAE,WAAO,QAAQ,KAAK;AAAA,EAAG;AACjD,WAAS,OAAO,OAAO;AAAE,WAAO,SAAS,KAAK;AAAA,EAAG;AACjD,WAAS,OAAO,GAAG,GAAG;AAAE,QAAI,EAAE,CAAC,GAAG,EAAE,MAAM,GAAG,EAAE,OAAQ,QAAO,EAAE,CAAC,EAAE,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC;AAAA,EAAG;AACrF;AAuBA,IAAM,iBAAiB;AASvB,SAAS,cAAc,UAAU;AAC7B,QAAM,cAAc,SAAS,KAAK,YAAY,IAAI,kBAAkB,QAAQ,EAAE,OAAO,KAAK,CAAC,CAAC;AAC5F,QAAM,iBAAiB,kBAAkB,WAAW;AACpD,QAAM,CAAC,SAAS,OAAO,IAAI,eAAe,IAAI;AAC9C,SAAO;AAAA,IACH,QAAQ,yBAAyB,OAAO;AAAA,IACxC,UAAU,mBAAmB,OAAO;AAAA,EACxC;AACJ;AACA,eAAe,mBAAmB,QAAQ;AACtC,QAAM,eAAe,CAAC;AACtB,QAAM,SAAS,OAAO,UAAU;AAChC,SAAO,MAAM;AACT,UAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAC1C,QAAI,MAAM;AACN,aAAO,WAAW,mBAAmB,YAAY,CAAC;AAAA,IACtD;AACA,iBAAa,KAAK,KAAK;AAAA,EAC3B;AACJ;AACA,SAAS,yBAAyB,QAAQ;AACtC,SAAO,iBAAiB,MAAM,WAAW,UAAU,6BAA6B;AAC5E,UAAM,SAAS,OAAO,UAAU;AAChC,WAAO,MAAM;AACT,YAAM,EAAE,OAAO,KAAK,IAAI,MAAM,QAAQ,OAAO,KAAK,CAAC;AACnD,UAAI,MAAM;AACN;AAAA,MACJ;AACA,YAAM,MAAM,QAAQ,WAAW,KAAK,CAAC;AAAA,IACzC;AAAA,EACJ,CAAC;AACL;AAMA,SAAS,kBAAkB,aAAa;AACpC,QAAM,SAAS,YAAY,UAAU;AACrC,QAAM,SAAS,IAAI,eAAe;AAAA,IAC9B,MAAM,YAAY;AACd,UAAI,cAAc;AAClB,aAAO,KAAK;AACZ,eAAS,OAAO;AACZ,eAAO,OAAO,KAAK,EAAE,KAAK,CAAC,EAAE,OAAO,KAAK,MAAM;AAC3C,cAAI,MAAM;AACN,gBAAI,YAAY,KAAK,GAAG;AACpB,yBAAW,MAAM,IAAI,wBAAwB,wBAAwB,CAAC;AACtE;AAAA,YACJ;AACA,uBAAW,MAAM;AACjB;AAAA,UACJ;AACA,yBAAe;AACf,cAAI,QAAQ,YAAY,MAAM,cAAc;AAC5C,cAAI;AACJ,iBAAO,OAAO;AACV,gBAAI;AACA,+BAAiB,KAAK,MAAM,MAAM,CAAC,CAAC;AAAA,YACxC,SACO,GAAG;AACN,yBAAW,MAAM,IAAI,wBAAwB,iCAAiC,MAAM,CAAC,CAAC,GAAG,CAAC;AAC1F;AAAA,YACJ;AACA,uBAAW,QAAQ,cAAc;AACjC,0BAAc,YAAY,UAAU,MAAM,CAAC,EAAE,MAAM;AACnD,oBAAQ,YAAY,MAAM,cAAc;AAAA,UAC5C;AACA,iBAAO,KAAK;AAAA,QAChB,CAAC;AAAA,MACL;AAAA,IACJ;AAAA,EACJ,CAAC;AACD,SAAO;AACX;AAKA,SAAS,mBAAmB,WAAW;AACnC,QAAM,eAAe,UAAU,UAAU,SAAS,CAAC;AACnD,QAAM,qBAAqB;AAAA,IACvB,gBAAgB,iBAAiB,QAAQ,iBAAiB,SAAS,SAAS,aAAa;AAAA,EAC7F;AACA,aAAW,YAAY,WAAW;AAC9B,QAAI,SAAS,YAAY;AACrB,iBAAW,aAAa,SAAS,YAAY;AACzC,cAAM,IAAI,UAAU;AACpB,YAAI,CAAC,mBAAmB,YAAY;AAChC,6BAAmB,aAAa,CAAC;AAAA,QACrC;AACA,YAAI,CAAC,mBAAmB,WAAW,CAAC,GAAG;AACnC,6BAAmB,WAAW,CAAC,IAAI;AAAA,YAC/B,OAAO,UAAU;AAAA,UACrB;AAAA,QACJ;AAEA,2BAAmB,WAAW,CAAC,EAAE,mBAC7B,UAAU;AACd,2BAAmB,WAAW,CAAC,EAAE,oBAC7B,UAAU;AACd,2BAAmB,WAAW,CAAC,EAAE,eAAe,UAAU;AAC1D,2BAAmB,WAAW,CAAC,EAAE,gBAC7B,UAAU;AACd,2BAAmB,WAAW,CAAC,EAAE,gBAC7B,UAAU;AAKd,YAAI,UAAU,WAAW,UAAU,QAAQ,OAAO;AAC9C,cAAI,CAAC,mBAAmB,WAAW,CAAC,EAAE,SAAS;AAC3C,+BAAmB,WAAW,CAAC,EAAE,UAAU;AAAA,cACvC,MAAM,UAAU,QAAQ,QAAQ;AAAA,cAChC,OAAO,CAAC;AAAA,YACZ;AAAA,UACJ;AACA,gBAAM,UAAU,CAAC;AACjB,qBAAW,QAAQ,UAAU,QAAQ,OAAO;AACxC,gBAAI,KAAK,MAAM;AACX,sBAAQ,OAAO,KAAK;AAAA,YACxB;AACA,gBAAI,KAAK,cAAc;AACnB,sBAAQ,eAAe,KAAK;AAAA,YAChC;AACA,gBAAI,KAAK,gBAAgB;AACrB,sBAAQ,iBAAiB,KAAK;AAAA,YAClC;AACA,gBAAI,KAAK,qBAAqB;AAC1B,sBAAQ,sBAAsB,KAAK;AAAA,YACvC;AACA,gBAAI,OAAO,KAAK,OAAO,EAAE,WAAW,GAAG;AACnC,sBAAQ,OAAO;AAAA,YACnB;AACA,+BAAmB,WAAW,CAAC,EAAE,QAAQ,MAAM,KAAK,OAAO;AAAA,UAC/D;AAAA,QACJ;AAAA,MACJ;AAAA,IACJ;AACA,QAAI,SAAS,eAAe;AACxB,yBAAmB,gBAAgB,SAAS;AAAA,IAChD;AAAA,EACJ;AACA,SAAO;AACX;AAkBA,eAAe,sBAAsB,QAAQ,OAAO,QAAQ,gBAAgB;AACxE,QAAM,WAAW,MAAM;AAAA,IAAiB;AAAA,IAAO,KAAK;AAAA,IAAyB;AAAA;AAAA,IAChE;AAAA,IAAM,KAAK,UAAU,MAAM;AAAA,IAAG;AAAA,EAAc;AACzD,SAAO,cAAc,QAAQ;AACjC;AACA,eAAe,gBAAgB,QAAQ,OAAO,QAAQ,gBAAgB;AAClE,QAAM,WAAW,MAAM;AAAA,IAAiB;AAAA,IAAO,KAAK;AAAA,IAAkB;AAAA;AAAA,IACzD;AAAA,IAAO,KAAK,UAAU,MAAM;AAAA,IAAG;AAAA,EAAc;AAC1D,QAAM,eAAe,MAAM,SAAS,KAAK;AACzC,QAAM,mBAAmB,WAAW,YAAY;AAChD,SAAO;AAAA,IACH,UAAU;AAAA,EACd;AACJ;AAkBA,SAAS,wBAAwB,OAAO;AAEpC,MAAI,SAAS,MAAM;AACf,WAAO;AAAA,EACX,WACS,OAAO,UAAU,UAAU;AAChC,WAAO,EAAE,MAAM,UAAU,OAAO,CAAC,EAAE,MAAM,MAAM,CAAC,EAAE;AAAA,EACtD,WACS,MAAM,MAAM;AACjB,WAAO,EAAE,MAAM,UAAU,OAAO,CAAC,KAAK,EAAE;AAAA,EAC5C,WACS,MAAM,OAAO;AAClB,QAAI,CAAC,MAAM,MAAM;AACb,aAAO,EAAE,MAAM,UAAU,OAAO,MAAM,MAAM;AAAA,IAChD,OACK;AACD,aAAO;AAAA,IACX;AAAA,EACJ;AACJ;AACA,SAAS,iBAAiB,SAAS;AAC/B,MAAI,WAAW,CAAC;AAChB,MAAI,OAAO,YAAY,UAAU;AAC7B,eAAW,CAAC,EAAE,MAAM,QAAQ,CAAC;AAAA,EACjC,OACK;AACD,eAAW,gBAAgB,SAAS;AAChC,UAAI,OAAO,iBAAiB,UAAU;AAClC,iBAAS,KAAK,EAAE,MAAM,aAAa,CAAC;AAAA,MACxC,OACK;AACD,iBAAS,KAAK,YAAY;AAAA,MAC9B;AAAA,IACJ;AAAA,EACJ;AACA,SAAO,+CAA+C,QAAQ;AAClE;AASA,SAAS,+CAA+C,OAAO;AAC3D,QAAM,cAAc,EAAE,MAAM,QAAQ,OAAO,CAAC,EAAE;AAC9C,QAAM,kBAAkB,EAAE,MAAM,YAAY,OAAO,CAAC,EAAE;AACtD,MAAI,iBAAiB;AACrB,MAAI,qBAAqB;AACzB,aAAW,QAAQ,OAAO;AACtB,QAAI,sBAAsB,MAAM;AAC5B,sBAAgB,MAAM,KAAK,IAAI;AAC/B,2BAAqB;AAAA,IACzB,OACK;AACD,kBAAY,MAAM,KAAK,IAAI;AAC3B,uBAAiB;AAAA,IACrB;AAAA,EACJ;AACA,MAAI,kBAAkB,oBAAoB;AACtC,UAAM,IAAI,wBAAwB,4HAA4H;AAAA,EAClK;AACA,MAAI,CAAC,kBAAkB,CAAC,oBAAoB;AACxC,UAAM,IAAI,wBAAwB,kDAAkD;AAAA,EACxF;AACA,MAAI,gBAAgB;AAChB,WAAO;AAAA,EACX;AACA,SAAO;AACX;AACA,SAAS,uBAAuB,QAAQ,aAAa;AACjD,MAAI;AACJ,MAAI,kCAAkC;AAAA,IAClC,OAAO,gBAAgB,QAAQ,gBAAgB,SAAS,SAAS,YAAY;AAAA,IAC7E,kBAAkB,gBAAgB,QAAQ,gBAAgB,SAAS,SAAS,YAAY;AAAA,IACxF,gBAAgB,gBAAgB,QAAQ,gBAAgB,SAAS,SAAS,YAAY;AAAA,IACtF,OAAO,gBAAgB,QAAQ,gBAAgB,SAAS,SAAS,YAAY;AAAA,IAC7E,YAAY,gBAAgB,QAAQ,gBAAgB,SAAS,SAAS,YAAY;AAAA,IAClF,mBAAmB,gBAAgB,QAAQ,gBAAgB,SAAS,SAAS,YAAY;AAAA,IACzF,gBAAgB,KAAK,gBAAgB,QAAQ,gBAAgB,SAAS,SAAS,YAAY,mBAAmB,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,IAClJ,UAAU,CAAC;AAAA,EACf;AACA,QAAM,iCAAiC,OAAO,0BAA0B;AACxE,MAAI,OAAO,UAAU;AACjB,QAAI,gCAAgC;AAChC,YAAM,IAAI,oCAAoC,mFAAmF;AAAA,IACrI;AACA,oCAAgC,WAAW,OAAO;AAAA,EACtD,WACS,gCAAgC;AACrC,sCAAkC,OAAO,OAAO,OAAO,OAAO,CAAC,GAAG,+BAA+B,GAAG,OAAO,sBAAsB;AAAA,EACrI,OACK;AAED,UAAM,UAAU,iBAAiB,MAAM;AACvC,oCAAgC,WAAW,CAAC,OAAO;AAAA,EACvD;AACA,SAAO,EAAE,wBAAwB,gCAAgC;AACrE;AACA,SAAS,2BAA2B,QAAQ;AACxC,MAAI;AACJ,MAAI,OAAO,UAAU;AACjB,uBAAmB;AAAA,EACvB,OACK;AAED,UAAM,UAAU,iBAAiB,MAAM;AACvC,uBAAmB,EAAE,UAAU,CAAC,OAAO,EAAE;AAAA,EAC7C;AACA,MAAI,OAAO,mBAAmB;AAC1B,qBAAiB,oBAAoB,wBAAwB,OAAO,iBAAiB;AAAA,EACzF;AACA,SAAO;AACX;AACA,SAAS,wBAAwB,QAAQ;AACrC,MAAI,OAAO,WAAW,YAAY,MAAM,QAAQ,MAAM,GAAG;AACrD,UAAM,UAAU,iBAAiB,MAAM;AACvC,WAAO,EAAE,QAAQ;AAAA,EACrB;AACA,SAAO;AACX;AAmBA,IAAM,oBAAoB;AAAA,EACtB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACJ;AACA,IAAM,uBAAuB;AAAA,EACzB,MAAM,CAAC,QAAQ,YAAY;AAAA,EAC3B,UAAU,CAAC,kBAAkB;AAAA,EAC7B,OAAO,CAAC,QAAQ,gBAAgB,kBAAkB,qBAAqB;AAAA;AAAA,EAEvE,QAAQ,CAAC,MAAM;AACnB;AACA,SAAS,oBAAoB,SAAS;AAClC,MAAI,cAAc;AAClB,aAAW,eAAe,SAAS;AAC/B,UAAM,EAAE,MAAM,MAAM,IAAI;AACxB,QAAI,CAAC,eAAe,SAAS,QAAQ;AACjC,YAAM,IAAI,wBAAwB,iDAAiD,IAAI,EAAE;AAAA,IAC7F;AACA,QAAI,CAAC,eAAe,SAAS,IAAI,GAAG;AAChC,YAAM,IAAI,wBAAwB,4CAA4C,IAAI,yBAAyB,KAAK,UAAU,cAAc,CAAC,EAAE;AAAA,IAC/I;AACA,QAAI,CAAC,MAAM,QAAQ,KAAK,GAAG;AACvB,YAAM,IAAI,wBAAwB,6DAA6D;AAAA,IACnG;AACA,QAAI,MAAM,WAAW,GAAG;AACpB,YAAM,IAAI,wBAAwB,4CAA4C;AAAA,IAClF;AACA,UAAM,cAAc;AAAA,MAChB,MAAM;AAAA,MACN,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,kBAAkB;AAAA,MAClB,UAAU;AAAA,MACV,gBAAgB;AAAA,MAChB,qBAAqB;AAAA,IACzB;AACA,eAAW,QAAQ,OAAO;AACtB,iBAAW,OAAO,mBAAmB;AACjC,YAAI,OAAO,MAAM;AACb,sBAAY,GAAG,KAAK;AAAA,QACxB;AAAA,MACJ;AAAA,IACJ;AACA,UAAM,aAAa,qBAAqB,IAAI;AAC5C,eAAW,OAAO,mBAAmB;AACjC,UAAI,CAAC,WAAW,SAAS,GAAG,KAAK,YAAY,GAAG,IAAI,GAAG;AACnD,cAAM,IAAI,wBAAwB,sBAAsB,IAAI,oBAAoB,GAAG,QAAQ;AAAA,MAC/F;AAAA,IACJ;AACA,kBAAc;AAAA,EAClB;AACJ;AAqBA,IAAM,eAAe;AAOrB,IAAM,cAAN,MAAkB;AAAA,EACd,YAAY,QAAQ,OAAO,QAAQ,kBAAkB,CAAC,GAAG;AACrD,SAAK,QAAQ;AACb,SAAK,SAAS;AACd,SAAK,kBAAkB;AACvB,SAAK,WAAW,CAAC;AACjB,SAAK,eAAe,QAAQ,QAAQ;AACpC,SAAK,UAAU;AACf,QAAI,WAAW,QAAQ,WAAW,SAAS,SAAS,OAAO,SAAS;AAChE,0BAAoB,OAAO,OAAO;AAClC,WAAK,WAAW,OAAO;AAAA,IAC3B;AAAA,EACJ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,aAAa;AACf,UAAM,KAAK;AACX,WAAO,KAAK;AAAA,EAChB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,YAAY,SAAS,iBAAiB,CAAC,GAAG;AAC5C,QAAI,IAAI,IAAI,IAAI,IAAI,IAAI;AACxB,UAAM,KAAK;AACX,UAAM,aAAa,iBAAiB,OAAO;AAC3C,UAAM,yBAAyB;AAAA,MAC3B,iBAAiB,KAAK,KAAK,YAAY,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,MAC3E,mBAAmB,KAAK,KAAK,YAAY,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,MAC7E,QAAQ,KAAK,KAAK,YAAY,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,MAClE,aAAa,KAAK,KAAK,YAAY,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,MACvE,oBAAoB,KAAK,KAAK,YAAY,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,MAC9E,gBAAgB,KAAK,KAAK,YAAY,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,MAC1E,UAAU,CAAC,GAAG,KAAK,UAAU,UAAU;AAAA,IAC3C;AACA,UAAM,4BAA4B,OAAO,OAAO,OAAO,OAAO,CAAC,GAAG,KAAK,eAAe,GAAG,cAAc;AACvG,QAAI;AAEJ,SAAK,eAAe,KAAK,aACpB,KAAK,MAAM,gBAAgB,KAAK,SAAS,KAAK,OAAO,wBAAwB,yBAAyB,CAAC,EACvG,KAAK,CAAC,WAAW;AAClB,UAAIC;AACJ,UAAI,OAAO,SAAS,cAChB,OAAO,SAAS,WAAW,SAAS,GAAG;AACvC,aAAK,SAAS,KAAK,UAAU;AAC7B,cAAM,kBAAkB,OAAO,OAAO;AAAA,UAAE,OAAO,CAAC;AAAA;AAAA,UAE5C,MAAM;AAAA,QAAQ,IAAIA,MAAK,OAAO,SAAS,gBAAgB,QAAQA,QAAO,SAAS,SAASA,IAAG,CAAC,EAAE,OAAO;AACzG,aAAK,SAAS,KAAK,eAAe;AAAA,MACtC,OACK;AACD,cAAM,oBAAoB,wBAAwB,OAAO,QAAQ;AACjE,YAAI,mBAAmB;AACnB,kBAAQ,KAAK,mCAAmC,iBAAiB,wCAAwC;AAAA,QAC7G;AAAA,MACJ;AACA,oBAAc;AAAA,IAClB,CAAC;AACD,UAAM,KAAK;AACX,WAAO;AAAA,EACX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUA,MAAM,kBAAkB,SAAS,iBAAiB,CAAC,GAAG;AAClD,QAAI,IAAI,IAAI,IAAI,IAAI,IAAI;AACxB,UAAM,KAAK;AACX,UAAM,aAAa,iBAAiB,OAAO;AAC3C,UAAM,yBAAyB;AAAA,MAC3B,iBAAiB,KAAK,KAAK,YAAY,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,MAC3E,mBAAmB,KAAK,KAAK,YAAY,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,MAC7E,QAAQ,KAAK,KAAK,YAAY,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,MAClE,aAAa,KAAK,KAAK,YAAY,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,MACvE,oBAAoB,KAAK,KAAK,YAAY,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,MAC9E,gBAAgB,KAAK,KAAK,YAAY,QAAQ,OAAO,SAAS,SAAS,GAAG;AAAA,MAC1E,UAAU,CAAC,GAAG,KAAK,UAAU,UAAU;AAAA,IAC3C;AACA,UAAM,4BAA4B,OAAO,OAAO,OAAO,OAAO,CAAC,GAAG,KAAK,eAAe,GAAG,cAAc;AACvG,UAAM,gBAAgB,sBAAsB,KAAK,SAAS,KAAK,OAAO,wBAAwB,yBAAyB;AAEvH,SAAK,eAAe,KAAK,aACpB,KAAK,MAAM,aAAa,EAGxB,MAAM,CAAC,aAAa;AACrB,YAAM,IAAI,MAAM,YAAY;AAAA,IAChC,CAAC,EACI,KAAK,CAAC,iBAAiB,aAAa,QAAQ,EAC5C,KAAK,CAAC,aAAa;AACpB,UAAI,SAAS,cAAc,SAAS,WAAW,SAAS,GAAG;AACvD,aAAK,SAAS,KAAK,UAAU;AAC7B,cAAM,kBAAkB,OAAO,OAAO,CAAC,GAAG,SAAS,WAAW,CAAC,EAAE,OAAO;AAExE,YAAI,CAAC,gBAAgB,MAAM;AACvB,0BAAgB,OAAO;AAAA,QAC3B;AACA,aAAK,SAAS,KAAK,eAAe;AAAA,MACtC,OACK;AACD,cAAM,oBAAoB,wBAAwB,QAAQ;AAC1D,YAAI,mBAAmB;AACnB,kBAAQ,KAAK,yCAAyC,iBAAiB,wCAAwC;AAAA,QACnH;AAAA,MACJ;AAAA,IACJ,CAAC,EACI,MAAM,CAAC,MAAM;AAId,UAAI,EAAE,YAAY,cAAc;AAG5B,gBAAQ,MAAM,CAAC;AAAA,MACnB;AAAA,IACJ,CAAC;AACD,WAAO;AAAA,EACX;AACJ;AAkBA,eAAe,YAAY,QAAQ,OAAO,QAAQ,sBAAsB;AACpE,QAAM,WAAW,MAAM,iBAAiB,OAAO,KAAK,cAAc,QAAQ,OAAO,KAAK,UAAU,MAAM,GAAG,oBAAoB;AAC7H,SAAO,SAAS,KAAK;AACzB;AAkBA,eAAe,aAAa,QAAQ,OAAO,QAAQ,gBAAgB;AAC/D,QAAM,WAAW,MAAM,iBAAiB,OAAO,KAAK,eAAe,QAAQ,OAAO,KAAK,UAAU,MAAM,GAAG,cAAc;AACxH,SAAO,SAAS,KAAK;AACzB;AACA,eAAe,mBAAmB,QAAQ,OAAO,QAAQ,gBAAgB;AACrE,QAAM,oBAAoB,OAAO,SAAS,IAAI,CAAC,YAAY;AACvD,WAAO,OAAO,OAAO,OAAO,OAAO,CAAC,GAAG,OAAO,GAAG,EAAE,MAAM,CAAC;AAAA,EAC9D,CAAC;AACD,QAAM,WAAW,MAAM,iBAAiB,OAAO,KAAK,sBAAsB,QAAQ,OAAO,KAAK,UAAU,EAAE,UAAU,kBAAkB,CAAC,GAAG,cAAc;AACxJ,SAAO,SAAS,KAAK;AACzB;AAsBA,IAAM,kBAAN,MAAsB;AAAA,EAClB,YAAY,QAAQ,aAAa,kBAAkB,CAAC,GAAG;AACnD,SAAK,SAAS;AACd,SAAK,kBAAkB;AACvB,QAAI,YAAY,MAAM,SAAS,GAAG,GAAG;AAEjC,WAAK,QAAQ,YAAY;AAAA,IAC7B,OACK;AAED,WAAK,QAAQ,UAAU,YAAY,KAAK;AAAA,IAC5C;AACA,SAAK,mBAAmB,YAAY,oBAAoB,CAAC;AACzD,SAAK,iBAAiB,YAAY,kBAAkB,CAAC;AACrD,SAAK,QAAQ,YAAY;AACzB,SAAK,aAAa,YAAY;AAC9B,SAAK,oBAAoB,wBAAwB,YAAY,iBAAiB;AAC9E,SAAK,gBAAgB,YAAY;AAAA,EACrC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,gBAAgB,SAAS,iBAAiB,CAAC,GAAG;AAChD,QAAI;AACJ,UAAM,kBAAkB,2BAA2B,OAAO;AAC1D,UAAM,gCAAgC,OAAO,OAAO,OAAO,OAAO,CAAC,GAAG,KAAK,eAAe,GAAG,cAAc;AAC3G,WAAO,gBAAgB,KAAK,QAAQ,KAAK,OAAO,OAAO,OAAO,EAAE,kBAAkB,KAAK,kBAAkB,gBAAgB,KAAK,gBAAgB,OAAO,KAAK,OAAO,YAAY,KAAK,YAAY,mBAAmB,KAAK,mBAAmB,gBAAgB,KAAK,KAAK,mBAAmB,QAAQ,OAAO,SAAS,SAAS,GAAG,KAAK,GAAG,eAAe,GAAG,6BAA6B;AAAA,EACrX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAWA,MAAM,sBAAsB,SAAS,iBAAiB,CAAC,GAAG;AACtD,QAAI;AACJ,UAAM,kBAAkB,2BAA2B,OAAO;AAC1D,UAAM,gCAAgC,OAAO,OAAO,OAAO,OAAO,CAAC,GAAG,KAAK,eAAe,GAAG,cAAc;AAC3G,WAAO,sBAAsB,KAAK,QAAQ,KAAK,OAAO,OAAO,OAAO,EAAE,kBAAkB,KAAK,kBAAkB,gBAAgB,KAAK,gBAAgB,OAAO,KAAK,OAAO,YAAY,KAAK,YAAY,mBAAmB,KAAK,mBAAmB,gBAAgB,KAAK,KAAK,mBAAmB,QAAQ,OAAO,SAAS,SAAS,GAAG,KAAK,GAAG,eAAe,GAAG,6BAA6B;AAAA,EAC3X;AAAA;AAAA;AAAA;AAAA;AAAA,EAKA,UAAU,iBAAiB;AACvB,QAAI;AACJ,WAAO,IAAI,YAAY,KAAK,QAAQ,KAAK,OAAO,OAAO,OAAO,EAAE,kBAAkB,KAAK,kBAAkB,gBAAgB,KAAK,gBAAgB,OAAO,KAAK,OAAO,YAAY,KAAK,YAAY,mBAAmB,KAAK,mBAAmB,gBAAgB,KAAK,KAAK,mBAAmB,QAAQ,OAAO,SAAS,SAAS,GAAG,KAAK,GAAG,eAAe,GAAG,KAAK,eAAe;AAAA,EAC5W;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,YAAY,SAAS,iBAAiB,CAAC,GAAG;AAC5C,UAAM,kBAAkB,uBAAuB,SAAS;AAAA,MACpD,OAAO,KAAK;AAAA,MACZ,kBAAkB,KAAK;AAAA,MACvB,gBAAgB,KAAK;AAAA,MACrB,OAAO,KAAK;AAAA,MACZ,YAAY,KAAK;AAAA,MACjB,mBAAmB,KAAK;AAAA,MACxB,eAAe,KAAK;AAAA,IACxB,CAAC;AACD,UAAM,gCAAgC,OAAO,OAAO,OAAO,OAAO,CAAC,GAAG,KAAK,eAAe,GAAG,cAAc;AAC3G,WAAO,YAAY,KAAK,QAAQ,KAAK,OAAO,iBAAiB,6BAA6B;AAAA,EAC9F;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,aAAa,SAAS,iBAAiB,CAAC,GAAG;AAC7C,UAAM,kBAAkB,wBAAwB,OAAO;AACvD,UAAM,gCAAgC,OAAO,OAAO,OAAO,OAAO,CAAC,GAAG,KAAK,eAAe,GAAG,cAAc;AAC3G,WAAO,aAAa,KAAK,QAAQ,KAAK,OAAO,iBAAiB,6BAA6B;AAAA,EAC/F;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,mBAAmB,0BAA0B,iBAAiB,CAAC,GAAG;AACpE,UAAM,gCAAgC,OAAO,OAAO,OAAO,OAAO,CAAC,GAAG,KAAK,eAAe,GAAG,cAAc;AAC3G,WAAO,mBAAmB,KAAK,QAAQ,KAAK,OAAO,0BAA0B,6BAA6B;AAAA,EAC9G;AACJ;AAsBA,IAAM,qBAAN,MAAyB;AAAA,EACrB,YAAY,QAAQ;AAChB,SAAK,SAAS;AAAA,EAClB;AAAA;AAAA;AAAA;AAAA,EAIA,mBAAmB,aAAa,gBAAgB;AAC5C,QAAI,CAAC,YAAY,OAAO;AACpB,YAAM,IAAI,wBAAwB,0FACiC;AAAA,IACvE;AACA,WAAO,IAAI,gBAAgB,KAAK,QAAQ,aAAa,cAAc;AAAA,EACvE;AAAA;AAAA;AAAA;AAAA,EAIA,oCAAoC,eAAe,aAAa,gBAAgB;AAC5E,QAAI,CAAC,cAAc,MAAM;AACrB,YAAM,IAAI,oCAAoC,6CAA6C;AAAA,IAC/F;AACA,QAAI,CAAC,cAAc,OAAO;AACtB,YAAM,IAAI,oCAAoC,8CAA8C;AAAA,IAChG;AAKA,UAAM,uBAAuB,CAAC,SAAS,mBAAmB;AAC1D,eAAW,OAAO,sBAAsB;AACpC,WAAK,gBAAgB,QAAQ,gBAAgB,SAAS,SAAS,YAAY,GAAG,MAC1E,cAAc,GAAG,MAChB,gBAAgB,QAAQ,gBAAgB,SAAS,SAAS,YAAY,GAAG,OAAO,cAAc,GAAG,GAAG;AACrG,YAAI,QAAQ,SAAS;AACjB,gBAAM,kBAAkB,YAAY,MAAM,WAAW,SAAS,IACxD,YAAY,MAAM,QAAQ,WAAW,EAAE,IACvC,YAAY;AAClB,gBAAM,oBAAoB,cAAc,MAAM,WAAW,SAAS,IAC5D,cAAc,MAAM,QAAQ,WAAW,EAAE,IACzC,cAAc;AACpB,cAAI,oBAAoB,mBAAmB;AACvC;AAAA,UACJ;AAAA,QACJ;AACA,cAAM,IAAI,oCAAoC,wBAAwB,GAAG,+BAChE,YAAY,GAAG,CAAC,wBAAwB,cAAc,GAAG,CAAC,GAAG;AAAA,MAC1E;AAAA,IACJ;AACA,UAAM,uBAAuB,OAAO,OAAO,OAAO,OAAO,CAAC,GAAG,WAAW,GAAG,EAAE,OAAO,cAAc,OAAO,OAAO,cAAc,OAAO,YAAY,cAAc,YAAY,mBAAmB,cAAc,mBAAmB,cAAc,CAAC;AAC9O,WAAO,IAAI,gBAAgB,KAAK,QAAQ,sBAAsB,cAAc;AAAA,EAChF;AACJ;;;AC16CO,SAAS,2BAEhB,KAAK;AACD,MAAI,OAAO,QAAQ,YAAY,QAAQ,MAAM;AACzC,UAAM,SAAS,EAAE,GAAG,IAAI;AACxB,QAAI,0BAA0B,QAAQ;AAClC,aAAO,OAAO;AAAA,IAClB;AACA,QAAI,aAAa,QAAQ;AACrB,aAAO,OAAO;AAAA,IAClB;AACA,eAAW,OAAO,QAAQ;AACtB,UAAI,OAAO,QAAQ;AACf,YAAI,MAAM,QAAQ,OAAO,GAAG,CAAC,GAAG;AAC5B,iBAAO,GAAG,IAAI,OAAO,GAAG,EAAE,IAAI,0BAA0B;AAAA,QAC5D,WACS,OAAO,OAAO,GAAG,MAAM,YAAY,OAAO,GAAG,MAAM,MAAM;AAC9D,iBAAO,GAAG,IAAI,2BAA2B,OAAO,GAAG,CAAC;AAAA,QACxD;AAAA,MACJ;AAAA,IACJ;AACA,WAAO;AAAA,EACX;AACA,SAAO;AACX;AACO,SAAS,4BAEhB,QAAQ;AAGJ,QAAM,aAAa,2BAA2B,gBAAgB,MAAM,CAAC;AACrE,QAAM,EAAE,SAAS,GAAG,KAAK,IAAI;AAC7B,SAAO;AACX;AACO,SAAS,6BAEhB,QAAQ;AAIJ,QAAM,aAAa,2BAA2B,MAAM;AACpD,QAAM,EAAE,SAAS,GAAG,KAAK,IAAI;AAC7B,SAAO;AACX;;;ACxCO,SAAS,iBAAiB,SAAS;AACtC,QAAM,OAAO,QAAQ,SAAS;AAC9B,MAAI,YAAY,WAAW,OAAO,GAAG;AACjC,WAAO,QAAQ;AAAA,EACnB;AACA,MAAI,SAAS,QAAQ;AACjB,WAAO;AAAA,EACX;AACA,SAAO,QAAQ,QAAQ;AAC3B;AAOO,SAAS,oBAAoB,QAAQ;AACxC,UAAQ,QAAQ;AAAA,IAKZ,KAAK;AAAA,IACL,KAAK;AACD,aAAO;AAAA,IACX,KAAK;AACD,aAAO;AAAA,IACX,KAAK;AACD,aAAO;AAAA,IACX,KAAK;AAAA,IACL,KAAK;AACD,aAAO;AAAA,IACX;AACI,YAAM,IAAI,MAAM,iCAAiC,MAAM,EAAE;AAAA,EACjE;AACJ;AACA,SAAS,oBAAoB,SAAS;AAClC,MAAI,cAAc,WAAW,UAAU,SAAS;AAC5C,WAAO;AAAA,MACH,YAAY;AAAA,QACR,UAAU,QAAQ;AAAA,QAClB,MAAM,QAAQ;AAAA,MAClB;AAAA,IACJ;AAAA,EACJ;AACA,MAAI,cAAc,WAAW,aAAa,SAAS;AAC/C,WAAO;AAAA,MACH,UAAU;AAAA,QACN,UAAU,QAAQ;AAAA,QAClB,SAAS,QAAQ;AAAA,MACrB;AAAA,IACJ;AAAA,EACJ;AACA,QAAM,IAAI,MAAM,uBAAuB;AAC3C;AACO,SAAS,6BAA6B,SAAS,mBAAmB;AACrE,MAAI,OAAO,QAAQ,YAAY,YAAY,QAAQ,YAAY,IAAI;AAC/D,WAAO,CAAC,EAAE,MAAM,QAAQ,QAAQ,CAAC;AAAA,EACrC;AACA,MAAI,gBAAgB,CAAC;AACrB,MAAI,oBAAoB,CAAC;AACzB,MAAI,eAAe,CAAC;AACpB,MAAI,gBAAgB,WAChB,MAAM,QAAQ,QAAQ,UAAU,KAChC,QAAQ,WAAW,SAAS,GAAG;AAC/B,oBAAgB,QAAQ,WAAW,IAAI,CAAC,QAAQ;AAAA,MAC5C,cAAc;AAAA,QACV,MAAM,GAAG;AAAA,QACT,MAAM,GAAG;AAAA,MACb;AAAA,IACJ,EAAE;AAAA,EACN,WACS,QAAQ,QAAQ,MAAM,UAAU,QAAQ,QAAQ,QAAQ,SAAS;AACtE,wBAAoB;AAAA,MAChB;AAAA,QACI,kBAAkB;AAAA,UACd,MAAM,QAAQ;AAAA,UACd,UAAU,QAAQ;AAAA,QACtB;AAAA,MACJ;AAAA,IACJ;AAAA,EACJ,WACS,MAAM,QAAQ,QAAQ,OAAO,GAAG;AACrC,mBAAe,QAAQ,QAAQ,IAAI,CAAC,MAAM;AAxFlD;AAyFY,UAAI,EAAE,SAAS,QAAQ;AACnB,eAAO;AAAA,UACH,MAAM,EAAE;AAAA,QACZ;AAAA,MACJ,WACS,EAAE,SAAS,kBAAkB;AAClC,eAAO;AAAA,UACH,gBAAgB,EAAE;AAAA,QACtB;AAAA,MACJ,WACS,EAAE,SAAS,uBAAuB;AACvC,eAAO;AAAA,UACH,qBAAqB,EAAE;AAAA,QAC3B;AAAA,MACJ;AACA,UAAI,EAAE,SAAS,aAAa;AACxB,YAAI,CAAC,mBAAmB;AACpB,gBAAM,IAAI,MAAM,oCAAoC;AAAA,QACxD;AACA,YAAI;AACJ,YAAI,OAAO,EAAE,cAAc,UAAU;AACjC,mBAAS,EAAE;AAAA,QACf,WACS,OAAO,EAAE,cAAc,YAAY,SAAS,EAAE,WAAW;AAC9D,mBAAS,EAAE,UAAU;AAAA,QACzB,OACK;AACD,gBAAM,IAAI,MAAM,iDAAiD;AAAA,QACrE;AACA,cAAM,CAAC,IAAI,IAAI,IAAI,OAAO,MAAM,GAAG;AACnC,YAAI,CAAC,GAAG,WAAW,OAAO,GAAG;AACzB,gBAAM,IAAI,MAAM,iDAAiD;AAAA,QACrE;AACA,cAAM,CAAC,UAAU,QAAQ,IAAI,GAAG,QAAQ,UAAU,EAAE,EAAE,MAAM,GAAG;AAC/D,YAAI,aAAa,UAAU;AACvB,gBAAM,IAAI,MAAM,iDAAiD;AAAA,QACrE;AACA,eAAO;AAAA,UACH,YAAY;AAAA,YACR;AAAA,YACA;AAAA,UACJ;AAAA,QACJ;AAAA,MACJ,WACS,EAAE,SAAS,SAAS;AACzB,eAAO,oBAAoB,CAAC;AAAA,MAChC,WACS,EAAE,SAAS,YAAY;AAC5B,eAAO;AAAA,UACH,cAAc;AAAA,YACV,MAAM,EAAE;AAAA,YACR,MAAM,EAAE;AAAA,UACZ;AAAA,QACJ;AAAA,MACJ,aACS,OAAE,SAAF,mBAAQ,SAAS;AAAA,MAEtB,EAAE,KAAK,MAAM,GAAG,EAAE,WAAW,KAC7B,UAAU,KACV,OAAO,EAAE,SAAS,UAAU;AAC5B,eAAO;AAAA,UACH,YAAY;AAAA,YACR,UAAU,EAAE;AAAA,YACZ,MAAM,EAAE;AAAA,UACZ;AAAA,QACJ;AAAA,MACJ;AACA,YAAM,IAAI,MAAM,wBAAwB,EAAE,IAAI,EAAE;AAAA,IACpD,CAAC;AAAA,EACL;AACA,SAAO,CAAC,GAAG,cAAc,GAAG,eAAe,GAAG,iBAAiB;AACnE;AACO,SAAS,6BAA6B,UAAU,mBAAmB,qCAAqC,OAAO;AAClH,SAAO,SAAS,OAAO,CAAC,KAAK,SAAS,UAAU;AAC5C,QAAI,CAAC,cAAc,OAAO,GAAG;AACzB,YAAM,IAAI,MAAM,2BAA2B;AAAA,IAC/C;AACA,UAAM,SAAS,iBAAiB,OAAO;AACvC,QAAI,WAAW,YAAY,UAAU,GAAG;AACpC,YAAM,IAAI,MAAM,wCAAwC;AAAA,IAC5D;AACA,UAAM,OAAO,oBAAoB,MAAM;AACvC,UAAM,cAAc,IAAI,QAAQ,IAAI,QAAQ,MAAM;AAClD,QAAI,CAAC,IAAI,4BACL,eACA,YAAY,SAAS,MAAM;AAC3B,YAAM,IAAI,MAAM,kEAAkE;AAAA,IACtF;AACA,UAAM,QAAQ,6BAA6B,SAAS,iBAAiB;AACrE,QAAI,IAAI,0BAA0B;AAC9B,YAAMC,eAAc,IAAI,QAAQ,IAAI,QAAQ,SAAS,CAAC;AACtD,UAAI,CAACA,cAAa;AACd,cAAM,IAAI,MAAM,mFAAmF;AAAA,MACvG;AACA,MAAAA,aAAY,MAAM,KAAK,GAAG,KAAK;AAC/B,aAAO;AAAA,QACH,0BAA0B;AAAA,QAC1B,SAAS,IAAI;AAAA,MACjB;AAAA,IACJ;AACA,QAAI,aAAa;AACjB,QAAI,eAAe,cACd,eAAe,YAAY,CAAC,oCAAqC;AAElE,mBAAa;AAAA,IACjB;AACA,UAAM,UAAU;AAAA,MACZ,MAAM;AAAA,MACN;AAAA,IACJ;AACA,WAAO;AAAA,MACH,0BAA0B,WAAW,YAAY,CAAC;AAAA,MAClD,SAAS,CAAC,GAAG,IAAI,SAAS,OAAO;AAAA,IACrC;AAAA,EACJ,GAAG,EAAE,SAAS,CAAC,GAAG,0BAA0B,MAAM,CAAC,EAAE;AACzD;AACO,SAAS,qCAAqC,UAAU,OAAO;AA7MtE;AA+MI,MAAI,CAAC,SAAS,cACV,SAAS,WAAW,WAAW,KAC/B,CAAC,SAAS,WAAW,CAAC,GAAG;AACzB,WAAO;AAAA,MACH,aAAa,CAAC;AAAA,MACd,WAAW;AAAA,QACP,SAAS,SAAS;AAAA,MACtB;AAAA,IACJ;AAAA,EACJ;AACA,QAAM,gBAAgB,SAAS,cAAc;AAC7C,QAAM,CAAC,SAAS,IAAI,SAAS;AAC7B,QAAM,EAAE,SAAS,kBAAkB,GAAG,eAAe,IAAI;AACzD,MAAI;AACJ,OAAI,qDAAkB,MAAM,YAAW,KAAK,iBAAiB,MAAM,CAAC,EAAE,MAAM;AACxE,cAAU,iBAAiB,MAAM,CAAC,EAAE;AAAA,EACxC,OACK;AACD,cAAU,iBAAiB,MAAM,IAAI,CAAC,MAAM;AACxC,UAAI,UAAU,GAAG;AACb,eAAO;AAAA,UACH,MAAM;AAAA,UACN,MAAM,EAAE;AAAA,QACZ;AAAA,MACJ,WACS,oBAAoB,GAAG;AAC5B,eAAO;AAAA,UACH,MAAM;AAAA,UACN,gBAAgB,EAAE;AAAA,QACtB;AAAA,MACJ,WACS,yBAAyB,GAAG;AACjC,eAAO;AAAA,UACH,MAAM;AAAA,UACN,qBAAqB,EAAE;AAAA,QAC3B;AAAA,MACJ;AACA,aAAO;AAAA,IACX,CAAC;AAAA,EACL;AACA,MAAI,OAAO;AACX,MAAI,OAAO,YAAY,UAAU;AAC7B,WAAO;AAAA,EACX,WACS,UAAU,QAAQ,CAAC,GAAG;AAC3B,WAAO,QAAQ,CAAC,EAAE;AAAA,EACtB;AACA,QAAM,aAAa;AAAA,IACf;AAAA,IACA,SAAS,IAAI,UAAU;AAAA,MACnB;AAAA,MACA,YAAY,+CAAe,IAAI,CAAC,QAAQ;AAAA,QACpC,GAAG;AAAA,QACH,MAAM;AAAA,MACV;AAAA,MACA,mBAAmB;AAAA,QACf,GAAG;AAAA,MACP;AAAA,MACA,gBAAgB,+BAAO;AAAA,IAC3B,CAAC;AAAA,IACD;AAAA,EACJ;AACA,SAAO;AAAA,IACH,aAAa,CAAC,UAAU;AAAA,IACxB,WAAW;AAAA,MACP,YAAY;AAAA,QACR,eAAc,oCAAO,kBAAP,mBAAsB;AAAA,QACpC,mBAAkB,oCAAO,kBAAP,mBAAsB;AAAA,QACxC,cAAa,oCAAO,kBAAP,mBAAsB;AAAA,MACvC;AAAA,IACJ;AAAA,EACJ;AACJ;AACO,SAAS,4CAA4C,UAAU,OAAO;AACzE,MAAI,CAAC,SAAS,cAAc,SAAS,WAAW,WAAW,GAAG;AAC1D,WAAO;AAAA,EACX;AACA,QAAM,gBAAgB,SAAS,cAAc;AAC7C,QAAM,CAAC,SAAS,IAAI,SAAS;AAC7B,QAAM,EAAE,SAAS,kBAAkB,GAAG,eAAe,IAAI;AACzD,MAAI;AAEJ,OAAI,qDAAkB,UAClB,iBAAiB,MAAM,MAAM,CAAC,MAAM,UAAU,CAAC,GAAG;AAClD,cAAU,iBAAiB,MAAM,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE;AAAA,EAC/D,WACS,iBAAiB,OAAO;AAC7B,cAAU,iBAAiB,MAAM,IAAI,CAAC,MAAM;AACxC,UAAI,UAAU,GAAG;AACb,eAAO;AAAA,UACH,MAAM;AAAA,UACN,MAAM,EAAE;AAAA,QACZ;AAAA,MACJ,WACS,oBAAoB,GAAG;AAC5B,eAAO;AAAA,UACH,MAAM;AAAA,UACN,gBAAgB,EAAE;AAAA,QACtB;AAAA,MACJ,WACS,yBAAyB,GAAG;AACjC,eAAO;AAAA,UACH,MAAM;AAAA,UACN,qBAAqB,EAAE;AAAA,QAC3B;AAAA,MACJ;AACA,aAAO;AAAA,IACX,CAAC;AAAA,EACL;AACA,MAAI,OAAO;AACX,MAAI,WAAW,OAAO,YAAY,UAAU;AACxC,WAAO;AAAA,EACX,WACS,WAAW,OAAO,YAAY,YAAY,UAAU,QAAQ,CAAC,GAAG;AACrE,WAAO,QAAQ,CAAC,EAAE;AAAA,EACtB;AACA,QAAM,iBAAiB,CAAC;AACxB,MAAI,eAAe;AACf,mBAAe,KAAK,GAAG,cAAc,IAAI,CAAC,QAAQ;AAAA,MAC9C,GAAG;AAAA,MACH,MAAM,KAAK,UAAU,GAAG,IAAI;AAAA,MAC5B,OAAO,MAAM;AAAA,MACb,MAAM;AAAA,IACV,EAAE,CAAC;AAAA,EACP;AACA,SAAO,IAAI,oBAAoB;AAAA,IAC3B;AAAA,IACA,SAAS,IAAI,eAAe;AAAA,MACxB,SAAS,WAAW;AAAA,MACpB,MAAM,CAAC,mBAAmB,SAAY,iBAAiB;AAAA,MACvD,kBAAkB;AAAA;AAAA;AAAA,MAGlB,mBAAmB,CAAC;AAAA,MACpB,gBAAgB,MAAM;AAAA,IAC1B,CAAC;AAAA,IACD;AAAA,EACJ,CAAC;AACL;AACO,SAAS,2BAA2B,OAAO;AAC9C,MAAI,MAAM,MAAM,CAAC,SAAS,0BAA0B,QAChD,MAAM,QAAQ,KAAK,oBAAoB,CAAC,GAAG;AAC3C,WAAO;AAAA,EACX;AACA,SAAO;AAAA,IACH;AAAA,MACI,sBAAsB,MAAM,IAAI,CAAC,SAAS;AACtC,YAAI,gBAAgB,IAAI,GAAG;AACvB,gBAAM,aAAa,4BAA4B,KAAK,MAAM;AAC1D,iBAAO;AAAA,YACH,MAAM,KAAK;AAAA,YACX,aAAa,KAAK;AAAA,YAClB,YAAY;AAAA,UAChB;AAAA,QACJ;AACA,YAAI,aAAa,IAAI,GAAG;AACpB,iBAAO;AAAA,YACH,MAAM,KAAK,SAAS;AAAA,YACpB,aAAa,KAAK,SAAS,eAAe;AAAA,YAC1C,YAAY,6BAA6B,KAAK,SAAS,UAAU;AAAA,UACrE;AAAA,QACJ;AACA,eAAO;AAAA,MACX,CAAC;AAAA,IACL;AAAA,EACJ;AACJ;;;ACpXO,IAAM,sCAAN,cAAkD,oBAAoB;AAAA,EACzE,OAAO,UAAU;AACb,WAAO;AAAA,EACX;AAAA,EACA,YAAY,QAAQ;AAChB,UAAM,MAAM;AACZ,WAAO,eAAe,MAAM,gBAAgB;AAAA,MACxC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO,CAAC,aAAa,gBAAgB,gBAAgB;AAAA,IACzD,CAAC;AACD,WAAO,eAAe,MAAM,YAAY;AAAA,MACpC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AAED,WAAO,eAAe,MAAM,WAAW;AAAA,MACnC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AAED,WAAO,eAAe,MAAM,gBAAgB;AAAA,MACxC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,aAAa;AAAA,MACrC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,SAAK,UAAU,OAAO;AACtB,SAAK,eAAe,OAAO,gBAAgB,KAAK;AAChD,SAAK,YAAY,OAAO;AAAA,EAC5B;AAAA,EACA,MAAM,gBAAgB,QAAQ;AAC1B,QAAI,KAAK,cAAc,QAAW;AAC9B,aAAO;AAAA,IACX;AACA,UAAM,kBAAkB,MAAM,KAAK,UAAU,eAAe,MAAM;AAClE,QAAI,gBAAgB,SAAS;AACzB,aAAO,gBAAgB;AAAA,IAC3B,OACK;AACD,YAAM,IAAI,sBAAsB,2BAA2B,KAAK,UAAU,QAAQ,MAAM,CAAC,CAAC,aAAa,KAAK,UAAU,gBAAgB,MAAM,MAAM,CAAC,IAAI,KAAK,UAAU,QAAQ,MAAM,CAAC,CAAC;AAAA,IAC1L;AAAA,EACJ;AAAA,EACA,MAAM,YAAY,aAAa;AAC3B,UAAM,QAAQ,YAAY,QAAQ,CAAC,eAAe;AAC9C,YAAM,EAAE,QAAQ,IAAI;AACpB,UAAI,EAAE,gBAAgB,YAAY,CAAC,MAAM,QAAQ,QAAQ,UAAU,GAAG;AAClE,eAAO,CAAC;AAAA,MACZ;AACA,aAAO,QAAQ;AAAA,IACnB,CAAC;AACD,QAAI,MAAM,CAAC,MAAM,QAAW;AACxB,YAAM,IAAI,MAAM,0EAA0E;AAAA,IAC9F;AACA,UAAM,CAAC,IAAI,IAAI;AACf,UAAM,kBAAkB,MAAM,KAAK,gBAAgB,KAAK,IAAI;AAC5D,WAAO;AAAA,EACX;AACJ;;;ACjEO,SAAS,oBAAoB,OAAO,OAAO;AAE9C,QAAM,aAAa,aAAa,KAAK;AAErC,QAAM,aAAa,iBAAiB,YAAY,KAAK;AACrD,SAAO,EAAE,OAAO,YAAY,WAAW;AAC3C;AACA,SAAS,aAAa,OAAO;AACzB,MAAI,2BAA2B,CAAC;AAChC,QAAM,aAAa,CAAC;AACpB,QAAM,QAAQ,CAAC,SAAS;AACpB,QAAI,gBAAgB,IAAI,GAAG;AACvB,YAAM,CAAC,aAAa,IAAI,2BAA2B;AAAA,QAC/C;AAAA,MACJ,CAAC;AACD,UAAI,cAAc,sBAAsB;AACpC,iCAAyB,KAAK,GAAG,cAAc,oBAAoB;AAAA,MACvE;AAAA,IACJ,WACS,aAAa,IAAI,GAAG;AACzB,YAAM,EAAE,qBAAqB,IAAI,yBAAyB,IAAI;AAC9D,UAAI,sBAAsB;AACtB,iCAAyB,KAAK,GAAG,oBAAoB;AAAA,MACzD,OACK;AACD,cAAM,IAAI,MAAM,+DAA+D;AAAA,MACnF;AAAA,IACJ,OACK;AACD,iBAAW,KAAK,IAAI;AAAA,IACxB;AAAA,EACJ,CAAC;AACD,QAAM,2BAA2B,WAAW,KAAK,CAAC,MAAM,0BAA0B,CAAC;AACnF,MAAI,0BAA0B;AAC1B,WAAO,WAAW,IAAI,CAAC,SAAS;AAC5B,WAAI,qEAA0B,UAAS,KACnC,0BAA0B,MAAM;AAChC,cAAM,UAAU;AAAA,UACZ,sBAAsB;AAAA,YAClB,GAAI,KAAK,wBAAwB,CAAC;AAAA,YAClC,GAAG;AAAA,UACP;AAAA,QACJ;AAEA,mCAA2B,CAAC;AAC5B,eAAO;AAAA,MACX;AACA,aAAO;AAAA,IACX,CAAC;AAAA,EACL;AACA,SAAO;AAAA,IACH,GAAG;AAAA,IACH,GAAI,yBAAyB,SAAS,IAChC;AAAA,MACE;AAAA,QACI,sBAAsB;AAAA,MAC1B;AAAA,IACJ,IACE,CAAC;AAAA,EACX;AACJ;AACA,SAAS,yBAAyB,MAAM;AACpC,SAAO;AAAA,IACH,sBAAsB;AAAA,MAClB;AAAA,QACI,MAAM,KAAK,SAAS;AAAA,QACpB,aAAa,KAAK,SAAS;AAAA,QAC3B,YAAY,2BAA2B,KAAK,SAAS,UAAU;AAAA,MACnE;AAAA,IACJ;AAAA,EACJ;AACJ;AACA,SAAS,iBAAiB,YAAY,OAAO;AACzC,MAAI,CAAC,WAAW,UAAU,CAAC;AACvB,WAAO;AACX,QAAM,EAAE,YAAY,qBAAqB,IAAI;AAC7C,QAAM,UAAU;AAAA,IACZ,KAAK,oBAAoB;AAAA,IACzB,MAAM,oBAAoB;AAAA,IAC1B,MAAM,oBAAoB;AAAA,EAC9B;AACA,MAAI,cAAc,CAAC,OAAO,QAAQ,MAAM,EAAE,SAAS,UAAU,GAAG;AAC5D,WAAO;AAAA,MACH,uBAAuB;AAAA,QACnB,MAAM,QAAQ,UAAU,KAAK;AAAA,QAC7B;AAAA,MACJ;AAAA,IACJ;AAAA,EACJ;AACA,MAAI,OAAO,eAAe,YAAY,sBAAsB;AACxD,WAAO;AAAA,MACH,uBAAuB;AAAA,QACnB,MAAM,oBAAoB;AAAA,QAC1B,sBAAsB;AAAA,UAClB,GAAI,wBAAwB,CAAC;AAAA,UAC7B,GAAI,cAAc,OAAO,eAAe,WAAW,CAAC,UAAU,IAAI,CAAC;AAAA,QACvE;AAAA,MACJ;AAAA,IACJ;AAAA,EACJ;AACA,SAAO;AACX;;;ACuRO,IAAM,yBAAN,cAAqC,cAAc;AAAA,EACtD,OAAO,UAAU;AACb,WAAO;AAAA,EACX;AAAA,EACA,IAAI,aAAa;AACb,WAAO;AAAA,MACH,QAAQ;AAAA,IACZ;AAAA,EACJ;AAAA,EACA,IAAI,aAAa;AACb,WAAO;AAAA,MACH,QAAQ;AAAA,IACZ;AAAA,EACJ;AAAA,EACA,IAAI,qBAAqB;AACrB,WAAQ,KAAK,MAAM,SAAS,QAAQ,KAChC,KAAK,MAAM,WAAW,YAAY,KAClC,KAAK,MAAM,WAAW,UAAU;AAAA,EACxC;AAAA,EACA,YAAY,QAAQ;AApZxB;AAqZQ,UAAM,UAAU,CAAC,CAAC;AAClB,WAAO,eAAe,MAAM,mBAAmB;AAAA,MAC3C,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,gBAAgB;AAAA,MACxC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO,CAAC,aAAa,eAAe,cAAc;AAAA,IACtD,CAAC;AACD,WAAO,eAAe,MAAM,aAAa;AAAA,MACrC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,SAAS;AAAA,MACjC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,eAAe;AAAA,MACvC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,mBAAmB;AAAA,MAC3C,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,QAAQ;AAAA,MAChC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,QAAQ;AAAA,MAChC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,iBAAiB;AAAA,MACzC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO,CAAC;AAAA,IACZ,CAAC;AACD,WAAO,eAAe,MAAM,kBAAkB;AAAA,MAC1C,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,UAAU;AAAA,MAClC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,aAAa;AAAA,MACrC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,eAAe;AAAA,MACvC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,sCAAsC;AAAA,MAC9D,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,UAAU;AAAA,MAClC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,SAAK,cACD,sCAAQ,UAAR,mBAAe,QAAQ,aAAa,UAChC,sCAAQ,cAAR,mBAAmB,QAAQ,aAAa,QACxC,KAAK;AACb,SAAK,QAAQ,KAAK;AAClB,SAAK,mBAAkB,iCAAQ,oBAAmB,KAAK;AACvD,QAAI,KAAK,mBAAmB,KAAK,kBAAkB,GAAG;AAClD,YAAM,IAAI,MAAM,8CAA8C;AAAA,IAClE;AACA,SAAK,eAAc,iCAAQ,gBAAe,KAAK;AAC/C,QAAI,KAAK,gBAAgB,KAAK,cAAc,KAAK,KAAK,cAAc,IAAI;AACpE,YAAM,IAAI,MAAM,iDAAiD;AAAA,IACrE;AACA,SAAK,QAAO,iCAAQ,SAAQ,KAAK;AACjC,QAAI,KAAK,QAAQ,KAAK,OAAO,GAAG;AAC5B,YAAM,IAAI,MAAM,mCAAmC;AAAA,IACvD;AACA,QAAI,KAAK,QAAQ,KAAK,OAAO,GAAG;AAC5B,YAAM,IAAI,MAAM,yBAAyB;AAAA,IAC7C;AACA,SAAK,QAAO,iCAAQ,SAAQ,KAAK;AACjC,QAAI,KAAK,QAAQ,KAAK,OAAO,GAAG;AAC5B,YAAM,IAAI,MAAM,mCAAmC;AAAA,IACvD;AACA,SAAK,iBAAgB,iCAAQ,kBAAiB,KAAK;AACnD,SAAK,UAAS,iCAAQ,WAAU,uBAAuB,gBAAgB;AACvE,QAAI,CAAC,KAAK,QAAQ;AACd,YAAM,IAAI,MAAM,6JAGwB;AAAA,IAC5C;AACA,SAAK,kBAAiB,iCAAQ,mBAAkB,KAAK;AACrD,QAAI,KAAK,kBAAkB,KAAK,eAAe,SAAS,GAAG;AACvD,YAAM,oBAAoB,IAAI,IAAI,KAAK,eAAe,IAAI,CAAC,MAAM,EAAE,QAAQ,CAAC;AAC5E,UAAI,kBAAkB,SAAS,KAAK,eAAe,QAAQ;AACvD,cAAM,IAAI,MAAM,yDAAyD;AAAA,MAC7E;AAAA,IACJ;AACA,SAAK,aAAY,iCAAQ,cAAa,KAAK;AAC3C,SAAK,SAAS,IAAI,mBAAa,KAAK,MAAM,EAAE,mBAAmB;AAAA,MAC3D,OAAO,KAAK;AAAA,MACZ,gBAAgB,KAAK;AAAA,MACrB,kBAAkB;AAAA,QACd,gBAAgB;AAAA,QAChB,eAAe,KAAK;AAAA,QACpB,iBAAiB,KAAK;AAAA,QACtB,aAAa,KAAK;AAAA,QAClB,MAAM,KAAK;AAAA,QACX,MAAM,KAAK;AAAA,QACX,IAAI,iCAAQ,QAAO,EAAE,kBAAkB,mBAAmB,IAAI,CAAC;AAAA,MACnE;AAAA,IACJ,GAAG;AAAA,MACC,YAAY,iCAAQ;AAAA,MACpB,SAAS,iCAAQ;AAAA,IACrB,CAAC;AACD,SAAK,eAAc,iCAAQ,gBAAe,KAAK;AAAA,EACnD;AAAA,EACA,iBAAiB,eAAe,aAAa,gBAAgB;AACzD,QAAI,CAAC,KAAK;AACN;AACJ,SAAK,SAAS,IAAI,mBAAa,KAAK,MAAM,EAAE,oCAAoC,eAAe,aAAa,cAAc;AAAA,EAC9H;AAAA,EACA,IAAI,uBAAuB;AACvB,WAAO,OAAO,KAAK,uCAAuC,YACpD,CAAC,KAAK,qCACN,KAAK;AAAA,EACf;AAAA,EACA,IAAI,8BAA8B;AAI9B,QAAI,KAAK,cAAc,sBAAsB;AACzC,aAAO;AAAA,IACX,WACS,KAAK,UAAU,WAAW,mBAAmB,GAAG;AACrD,aAAO;AAAA,IACX,WACS,KAAK,UAAU,WAAW,uBAAuB,GAAG;AACzD,aAAO;AAAA,IACX,WACS,KAAK,cAAc,cAAc;AAEtC,aAAO;AAAA,IACX;AACA,WAAO;AAAA,EACX;AAAA,EACA,YAAY,SAAS;AACjB,WAAO;AAAA,MACH,aAAa;AAAA,MACb,eAAe,KAAK;AAAA,MACpB,eAAe;AAAA,MACf,gBAAgB,KAAK,OAAO,iBAAiB;AAAA,MAC7C,eAAe,KAAK,OAAO,iBAAiB;AAAA,MAC5C,SAAS,QAAQ;AAAA,IACrB;AAAA,EACJ;AAAA,EACA,oBAAoB;AAChB,WAAO,CAAC;AAAA,EACZ;AAAA,EACA,WAAW;AACP,WAAO;AAAA,EACX;AAAA,EACA,UAAU,OAAO,QAAQ;AAvlB7B;AAwlBQ,WAAO,KAAK,KAAK,EAAE,QAAO,yBAAoB,KAAK,MAAzB,mBAA4B,OAAO,GAAG,OAAO,CAAC;AAAA,EAC5E;AAAA,EACA,iBAAiB,SAAS;AA1lB9B;AA2lBQ,UAAM,mBAAiB,wCAAS,UAAT,mBAAgB,UACjC,oBAAoB,QAAQ,OAAO;AAAA,MACjC,YAAY,QAAQ;AAAA,MACpB,sBAAsB,QAAQ;AAAA,IAClC,CAAC,IACC;AACN,WAAO;AAAA,MACH,IAAI,iDAAgB,SAAQ,EAAE,OAAO,eAAe,MAAM,IAAI,CAAC;AAAA,MAC/D,IAAI,iDAAgB,cACd,EAAE,YAAY,eAAe,WAAW,IACxC,CAAC;AAAA,IACX;AAAA,EACJ;AAAA,EACA,MAAM,UAAU,UAAU,SAAS,YAAY;AAxmBnD;AAymBQ,UAAM,SAAS,6BAA6B,UAAU,KAAK,oBAAoB,KAAK,oBAAoB;AACxG,QAAI,eAAe;AACnB,QAAI,OAAO,CAAC,EAAE,SAAS,UAAU;AAC7B,YAAM,CAAC,iBAAiB,IAAI;AAC5B,WAAK,OAAO,oBAAoB;AAChC,qBAAe,OAAO,MAAM,CAAC;AAAA,IACjC;AACA,UAAM,aAAa,KAAK,iBAAiB,OAAO;AAEhD,QAAI,KAAK,WAAW;AAChB,YAAM,aAAa,CAAC;AACpB,YAAM,SAAS,KAAK,sBAAsB,UAAU,SAAS,UAAU;AACvE,YAAM,cAAc,CAAC;AACrB,uBAAiB,SAAS,QAAQ;AAC9B,cAAM,UAAQ,WAAM,mBAAN,mBAAsB,eAAc;AAClD,YAAI,YAAY,KAAK,MAAM,QAAW;AAClC,sBAAY,KAAK,IAAI;AAAA,QACzB,OACK;AACD,sBAAY,KAAK,IAAI,YAAY,KAAK,EAAE,OAAO,KAAK;AAAA,QACxD;AAAA,MACJ;AACA,YAAM,cAAc,OAAO,QAAQ,WAAW,EACzC,KAAK,CAAC,CAAC,IAAI,GAAG,CAAC,IAAI,MAAM,SAAS,MAAM,EAAE,IAAI,SAAS,MAAM,EAAE,CAAC,EAChE,IAAI,CAAC,CAAC,GAAG,KAAK,MAAM,KAAK;AAC9B,aAAO,EAAE,aAAa,WAAW,EAAE,qBAAqB,WAAW,EAAE;AAAA,IACzE;AACA,UAAM,MAAM,MAAM,KAAK,oBAAoB;AAAA,MACvC,GAAG;AAAA,MACH,UAAU;AAAA,IACd,CAAC;AACD,QAAI;AACJ,QAAI,mBAAmB,IAAI,UAAU;AACjC,YAAM,qBAAqB,IAAI,SAAS;AACxC,sBAAgB;AAAA,QACZ,cAAc,mBAAmB,oBAAoB;AAAA,QACrD,eAAe,mBAAmB,wBAAwB;AAAA,QAC1D,cAAc,mBAAmB,mBAAmB;AAAA,MACxD;AAAA,IACJ;AACA,UAAM,mBAAmB,qCAAqC,IAAI,UAAU;AAAA,MACxE;AAAA,IACJ,CAAC;AACD,WAAM,yCAAY,kBAAkB,iBAAiB,YAAY,CAAC,EAAE,QAAQ;AAC5E,WAAO;AAAA,EACX;AAAA,EACA,OAAO,sBAAsB,UAAU,SAAS,YAAY;AACxD,UAAM,SAAS,6BAA6B,UAAU,KAAK,oBAAoB,KAAK,oBAAoB;AACxG,QAAI,eAAe;AACnB,QAAI,OAAO,CAAC,EAAE,SAAS,UAAU;AAC7B,YAAM,CAAC,iBAAiB,IAAI;AAC5B,WAAK,OAAO,oBAAoB;AAChC,qBAAe,OAAO,MAAM,CAAC;AAAA,IACjC;AACA,UAAM,aAAa,KAAK,iBAAiB,OAAO;AAChD,UAAM,UAAU;AAAA,MACZ,GAAG;AAAA,MACH,UAAU;AAAA,IACd;AACA,UAAM,SAAS,MAAM,KAAK,OAAO,gBAAgB,EAAE,QAAQ,mCAAS,OAAO,GAAG,YAAY;AACtF,YAAM,EAAE,QAAAC,QAAO,IAAI,MAAM,KAAK,OAAO,sBAAsB,OAAO;AAClE,aAAOA;AAAA,IACX,CAAC;AACD,QAAI;AACJ,QAAI,QAAQ;AACZ,qBAAiB,YAAY,QAAQ;AACjC,UAAI,mBAAmB,YACnB,KAAK,gBAAgB,SACrB,QAAQ,gBAAgB,OAAO;AAC/B,cAAM,qBAAqB,SAAS;AACpC,YAAI,CAAC,eAAe;AAChB,0BAAgB;AAAA,YACZ,cAAc,mBAAmB,oBAAoB;AAAA,YACrD,eAAe,mBAAmB,wBAAwB;AAAA,YAC1D,cAAc,mBAAmB,mBAAmB;AAAA,UACxD;AAAA,QACJ,OACK;AAGD,gBAAM,mBAAmB,mBAAmB,wBAAwB,KAChE,cAAc;AAClB,0BAAgB;AAAA,YACZ,cAAc;AAAA,YACd,eAAe;AAAA,YACf,cAAc;AAAA,UAClB;AAAA,QACJ;AAAA,MACJ;AACA,YAAM,QAAQ,4CAA4C,UAAU;AAAA,QAChE;AAAA,QACA;AAAA,MACJ,CAAC;AACD,eAAS;AACT,UAAI,CAAC,OAAO;AACR;AAAA,MACJ;AACA,YAAM;AACN,aAAM,yCAAY,kBAAkB,MAAM,QAAQ;AAAA,IACtD;AAAA,EACJ;AAAA,EACA,MAAM,oBAAoB,SAAS,SAAS;AACxC,WAAO,KAAK,OAAO,gBAAgB,EAAE,QAAQ,mCAAS,OAAO,GAAG,YAAY;AA/sBpF;AAgtBY,UAAI;AACA,eAAO,MAAM,KAAK,OAAO,gBAAgB,OAAO;AAAA,MAEpD,SACO,GAAG;AAEN,aAAI,OAAE,YAAF,mBAAW,SAAS,oBAAoB;AACxC,YAAE,SAAS;AAAA,QACf;AACA,cAAM;AAAA,MACV;AAAA,IACJ,CAAC;AAAA,EACL;AAAA,EACA,qBAAqB,cAAc,QAAQ;AAEvC,UAAM,SAAS;AACf,UAAM,OAAO,iCAAQ;AACrB,UAAM,SAAS,iCAAQ;AACvB,UAAM,aAAa,iCAAQ;AAC3B,QAAI,WAAW,YAAY;AACvB,YAAM,IAAI,MAAM,qEAAqE;AAAA,IACzF;AACA,QAAI,eAAe,QAAQ;AAC3B,QAAI;AACJ,QAAI;AACJ,QAAI,YAAY,MAAM,GAAG;AACrB,YAAM,aAAa,4BAA4B,MAAM;AACrD,cAAQ;AAAA,QACJ;AAAA,UACI,sBAAsB;AAAA,YAClB;AAAA,cACI,MAAM;AAAA,cACN,aAAa,WAAW,eAAe;AAAA,cACvC,YAAY;AAAA,YAChB;AAAA,UACJ;AAAA,QACJ;AAAA,MACJ;AACA,qBAAe,IAAI,oCAAoC;AAAA,QACnD,cAAc;AAAA,QACd,SAAS;AAAA,QACT,WAAW;AAAA,MACf,CAAC;AAAA,IACL,OACK;AACD,UAAI;AACJ,UAAI,OAAO,OAAO,SAAS,YACvB,OAAO,OAAO,eAAe,YAC7B,OAAO,cAAc,MAAM;AAC3B,mCAA2B;AAC3B,uBAAe,OAAO;AAAA,MAC1B,OACK;AACD,mCAA2B;AAAA,UACvB,MAAM;AAAA,UACN,aAAa,OAAO,eAAe;AAAA,UACnC,YAAY;AAAA,QAChB;AAAA,MACJ;AACA,cAAQ;AAAA,QACJ;AAAA,UACI,sBAAsB,CAAC,wBAAwB;AAAA,QACnD;AAAA,MACJ;AACA,qBAAe,IAAI,oCAAoC;AAAA,QACnD,cAAc;AAAA,QACd,SAAS;AAAA,MACb,CAAC;AAAA,IACL;AACA,UAAM,MAAM,KAAK,KAAK;AAAA,MAClB;AAAA,MACA,aAAa;AAAA,IACjB,CAAC;AACD,QAAI,CAAC,YAAY;AACb,aAAO,IAAI,KAAK,YAAY,EAAE,WAAW;AAAA,QACrC,SAAS;AAAA,MACb,CAAC;AAAA,IACL;AACA,UAAM,eAAe,oBAAoB,OAAO;AAAA;AAAA,MAE5C,QAAQ,CAAC,OAAOC,YAAW,aAAa,OAAO,MAAM,KAAKA,OAAM;AAAA,IACpE,CAAC;AACD,UAAM,aAAa,oBAAoB,OAAO;AAAA,MAC1C,QAAQ,MAAM;AAAA,IAClB,CAAC;AACD,UAAM,qBAAqB,aAAa,cAAc;AAAA,MAClD,WAAW,CAAC,UAAU;AAAA,IAC1B,CAAC;AACD,WAAO,iBAAiB,KAAK;AAAA,MACzB;AAAA,QACI,KAAK;AAAA,MACT;AAAA,MACA;AAAA,IACJ,CAAC,EAAE,WAAW;AAAA,MACV,SAAS;AAAA,IACb,CAAC;AAAA,EACL;AACJ;;;ACxxBO,IAAM,+BAAN,cAA2C,WAAW;AAAA,EACzD,YAAY,QAAQ;AA1BxB;AA2BQ,UAAM,UAAU,CAAC,CAAC;AAClB,WAAO,eAAe,MAAM,UAAU;AAAA,MAClC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,aAAa;AAAA,MACrC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,SAAS;AAAA,MACjC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,YAAY;AAAA,MACpC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,SAAS;AAAA,MACjC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,iBAAiB;AAAA,MACzC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,gBAAgB;AAAA,MACxC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,UAAU;AAAA,MAClC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,SAAK,cACD,sCAAQ,UAAR,mBAAe,QAAQ,aAAa,UAChC,sCAAQ,cAAR,mBAAmB,QAAQ,aAAa,QACxC,KAAK;AACb,SAAK,QAAQ,KAAK;AAClB,SAAK,YAAW,iCAAQ,aAAY,KAAK;AACzC,SAAK,SAAQ,iCAAQ,UAAS,KAAK;AACnC,QAAI,KAAK,SAAS,KAAK,aAAa,sBAAsB;AACtD,YAAM,IAAI,MAAM,8DAA8D;AAAA,IAClF;AACA,SAAK,UAAS,iCAAQ,WAAU,uBAAuB,gBAAgB;AACvE,QAAI,CAAC,KAAK,QAAQ;AACd,YAAM,IAAI,MAAM,oKAG8B;AAAA,IAClD;AACA,SAAK,SAAS,IAAI,mBAAmB,KAAK,MAAM,EAAE,mBAAmB;AAAA,MACjE,OAAO,KAAK;AAAA,IAChB,CAAC;AAAA,EACL;AAAA,EACA,kBAAkB,MAAM;AACpB,UAAM,cAAc,KAAK,gBAAgB,KAAK,QAAQ,OAAO,GAAG,IAAI;AACpE,WAAO;AAAA,MACH,SAAS,EAAE,MAAM,QAAQ,OAAO,CAAC,EAAE,MAAM,YAAY,CAAC,EAAE;AAAA,MACxD,UAAU,KAAK;AAAA,MACf,OAAO,KAAK;AAAA,IAChB;AAAA,EACJ;AAAA,EACA,MAAM,mBAAmB,MAAM;AAC3B,UAAM,MAAM,KAAK,kBAAkB,IAAI;AACvC,UAAM,MAAM,MAAM,KAAK,OAAO,aAAa,GAAG;AAC9C,WAAO,IAAI,UAAU,UAAU,CAAC;AAAA,EACpC;AAAA,EACA,MAAM,uBAAuB,WAAW;AACpC,UAAM,mBAAmB,WAAW,WAAW,KAAK,YAAY;AAChE,UAAM,qBAAqB,iBAAiB,IAAI,CAAC,WAAW;AAAA,MACxD,UAAU,MAAM,IAAI,CAAC,QAAQ,KAAK,kBAAkB,GAAG,CAAC;AAAA,IAC5D,EAAE;AACF,UAAM,YAAY,MAAM,QAAQ,WAAW,mBAAmB,IAAI,CAAC,QAAQ,KAAK,OAAO,mBAAmB,GAAG,CAAC,CAAC;AAC/G,UAAM,aAAa,UAAU,QAAQ,CAAC,KAAK,QAAQ;AAC/C,UAAI,IAAI,WAAW,aAAa;AAC5B,eAAO,IAAI,MAAM,WAAW,IAAI,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;AAAA,MACzD,OACK;AACD,eAAO,MAAM,iBAAiB,GAAG,EAAE,MAAM,EAAE,KAAK,CAAC,CAAC;AAAA,MACtD;AAAA,IACJ,CAAC;AACD,WAAO;AAAA,EACX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,WAAW,UAAU;AACjB,WAAO,KAAK,OAAO,KAAK,KAAK,mBAAmB,KAAK,IAAI,GAAG,QAAQ;AAAA,EACxE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,eAAe,WAAW;AACtB,WAAO,KAAK,OAAO,KAAK,KAAK,uBAAuB,KAAK,IAAI,GAAG,SAAS;AAAA,EAC7E;AACJ;",
  "names": ["SchemaType", "ExecutableCodeLanguage", "Outcome", "HarmCategory", "HarmBlockThreshold", "HarmProbability", "BlockReason", "FinishReason", "TaskType", "FunctionCallingMode", "DynamicRetrievalMode", "Task", "_a", "prevContent", "stream", "config"]
}
